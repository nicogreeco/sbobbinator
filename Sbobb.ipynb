{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicco\\miniconda3\\envs\\daily_notes\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import yt_dlp\n",
    "import assemblyai as aai\n",
    "import whisperx\n",
    "from faster_whisper import WhisperModel, BatchedInferencePipeline\n",
    "\n",
    "###############################################################################\n",
    "# 1. CONFIGURATION\n",
    "###############################################################################\n",
    "\n",
    "# Define the job name (for output file)\n",
    "job_name = input(\"Job name: \")\n",
    "\n",
    "# Load environment variables from config.env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('./config.env')\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "ASSEMBLYAI_API_KEY = os.getenv(\"ASSEMBLYAI_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Validate API keys based on selected transcription service\n",
    "# transcription_service = input(\"Choose transcription service (whisper/assemblyai): \").lower()\n",
    "transcription_service='whisper'\n",
    "if transcription_service not in ['whisper', 'assemblyai']:\n",
    "    raise ValueError(\"Invalid transcription service. Choose 'whisper' or 'assemblyai'\")\n",
    "\n",
    "if transcription_service == 'assemblyai' and not ASSEMBLYAI_API_KEY:\n",
    "    raise ValueError(\"ASSEMBLYAI_API_KEY not found in config.env\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in config.env\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Define OpenAI model to use\n",
    "OPENAI_MODEL = \"gpt-4.1-mini\"  # Ensure this model is accessible with your API key\n",
    "\n",
    "# Define chunking parameters\n",
    "CHUNK_WORD_TARGET = 500  # Target words per chunk\n",
    "MAX_SUMMARY_WORDS = 300  # Maximum words in running summary before summarization\n",
    "ENABLE_SUMMARY_SUMMARIZATION = True  # Toggle for summary summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 2. ASSEMBLYAI TRANSCRIPTION\n",
    "###############################################################################\n",
    "\n",
    "def download_youtube_audio(youtube_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Downloads the best available audio from a YouTube video, converts it to MP3 (192 kbps),\n",
    "    and saves it into ./audio/ with a proper file name.\n",
    "    \n",
    "    Returns the final path to the downloaded MP3 file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = './audio'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # We'll store the final file in ./audio/<title>.mp3\n",
    "    outtmpl = os.path.join(output_dir, \"%(title)s.%(ext)s\")\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",             # Download best-quality audio\n",
    "        \"outtmpl\": outtmpl,                    # Save to ./audio/<title>.<ext>\n",
    "        \"postprocessors\": [{\n",
    "            \"key\": \"FFmpegExtractAudio\",\n",
    "            \"preferredcodec\": \"mp3\",\n",
    "            \"preferredquality\": \"192\",         # ~192 kbps MP3\n",
    "        }],\n",
    "        \"cookiesfrombrowser\": (\"firefox\",),    # Use Firefox cookies if needed\n",
    "        \"quiet\": True,                         # Suppress non-error messages\n",
    "        \"no_warnings\": True\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(youtube_url, download=True)\n",
    "        # Prepare the base filename (e.g. 'My Song.m4a' before post-processing)\n",
    "        temp_path = ydl.prepare_filename(info)\n",
    "\n",
    "    # Because of the FFmpegExtractAudio postprocessor, the final file is .mp3\n",
    "    # We just replace the extension if needed:\n",
    "    base, _ = os.path.splitext(temp_path)\n",
    "    final_path = base + \".mp3\"\n",
    "\n",
    "    return final_path\n",
    "        \n",
    "def transcribe_audio_assemblyai(audio_url_or_path: str, language_code: str = \"en\", model: str='nano') -> aai.Transcript:\n",
    "    \"\"\"\n",
    "    Transcribe the audio from a local file path using AssemblyAI.\n",
    "    Returns the transcript object.\n",
    "    \"\"\"\n",
    "    # Set up AssemblyAI\n",
    "    aai.settings.api_key = ASSEMBLYAI_API_KEY\n",
    "    if model == 'nano':\n",
    "        config = aai.TranscriptionConfig(language_code=language_code, speech_model=aai.SpeechModel.nano)\n",
    "    elif model=='slam':\n",
    "        config = aai.TranscriptionConfig(language_code=language_code, speech_model=aai.SpeechModel.slam_1)\n",
    "    \n",
    "    transcriber = aai.Transcriber(config=config)\n",
    "\n",
    "    print(\"Uploading file to AssemblyAI for transcription...\")\n",
    "    transcript = transcriber.transcribe(audio_url_or_path)\n",
    "\n",
    "    # Poll for completion\n",
    "    while transcript.status not in ['completed', 'error']:\n",
    "        print(f\"Transcription status: {transcript.status}. Waiting...\")\n",
    "        time.sleep(5)\n",
    "        transcript = transcriber.get_transcription(transcript.id)\n",
    "\n",
    "    if transcript.status == aai.TranscriptStatus.error:\n",
    "        raise RuntimeError(f\"Transcription failed: {transcript.error}\")\n",
    "\n",
    "    return transcript\n",
    "\n",
    "def transcribe_audio(audio_source: str, language_code: str = \"en\", service: str = \"whisper\", model: str = 'small', batch_size: int = 1, device: str = 'cpu'):\n",
    "    \"\"\"\n",
    "    Unified transcription function that handles both Whisper and AssemblyAI.\n",
    "    Returns transcript text for consistency.\n",
    "    \"\"\"\n",
    "    # Handle YouTube URLs by downloading first\n",
    "    if \"youtube.com\" in audio_source or \"youtu.be\" in audio_source:\n",
    "        print(\"Detected YouTube URL. Downloading audio locally...\")\n",
    "        audio_source = download_youtube_audio(audio_source)\n",
    "        print(f\"Local file path: {audio_source}\")\n",
    "    \n",
    "    if service == \"whisper\":\n",
    "        return transcribe_audio_whisper(audio_source, language_code, model, batch_size, device)\n",
    "    elif service == \"assemblyai\":\n",
    "        transcript_obj = transcribe_audio_assemblyai(audio_source, language_code, model)\n",
    "        return transcript_obj.text\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transcription service: {service}\")\n",
    "\n",
    "###############################################################################\n",
    "# 3. CHUNKING THE TRANSCRIPT\n",
    "###############################################################################\n",
    "\n",
    "def chunk_text_by_sentences(transcript_text: str, chunk_word_target: int = 600) -> list:\n",
    "    \"\"\"\n",
    "    Splits the transcript text into chunks based on sentences, aiming for about\n",
    "    `chunk_word_target` words each. This works for plain text from Whisper.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Split into sentences using basic punctuation\n",
    "    sentences = re.split(r'[.!?]+', transcript_text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence_word_count = len(sentence.split())\n",
    "\n",
    "        # If adding this sentence exceeds the target and current chunk is not empty\n",
    "        if (current_word_count + sentence_word_count) > chunk_word_target and current_chunk:\n",
    "            chunk = \". \".join(current_chunk) + \".\"\n",
    "            chunks.append(chunk)\n",
    "            current_chunk = []\n",
    "            current_word_count = 0\n",
    "\n",
    "        current_chunk.append(sentence)\n",
    "        current_word_count += sentence_word_count\n",
    "\n",
    "    # Add any remaining sentences as the last chunk\n",
    "    if current_chunk:\n",
    "        chunk = \". \".join(current_chunk) + \".\"\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def chunk_text_by_paragraphs(transcript: aai.Transcript, chunk_word_target: int = 600) -> list:\n",
    "    \"\"\"\n",
    "    Splits the AssemblyAI transcript into chunks based on its paragraphs.\n",
    "    \"\"\"\n",
    "    paragraphs = transcript.get_paragraphs()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph_text = paragraph.text.strip()\n",
    "        if not paragraph_text:\n",
    "            continue\n",
    "\n",
    "        paragraph_word_count = len(paragraph_text.split())\n",
    "\n",
    "        if (current_word_count + paragraph_word_count) > chunk_word_target and current_chunk:\n",
    "            chunk = \"\\n\".join(current_chunk)\n",
    "            chunks.append(chunk)\n",
    "            current_chunk = []\n",
    "            current_word_count = 0\n",
    "\n",
    "        current_chunk.append(paragraph_text)\n",
    "        current_word_count += paragraph_word_count\n",
    "\n",
    "    if current_chunk:\n",
    "        chunk = \"\\n\".join(current_chunk)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "###############################################################################\n",
    "# 4. OPENAI REWRITING (PAGE-BY-PAGE)\n",
    "###############################################################################\n",
    "\n",
    "def rewrite_chunk_with_openai(chunk_text: str,\n",
    "                              model: str = OPENAI_MODEL,\n",
    "                              prev_summary: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Sends a chunk of text to OpenAI for rewriting in a 'professorial' register.\n",
    "\n",
    "    Optionally includes `prev_summary` - a short summary of all previously\n",
    "    processed chunks - as context for better continuity across chunks.\n",
    "\n",
    "    Returns the revised chunk as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build system prompt with instructions\n",
    "    system_prompt = (\n",
    "        \"You are an expert in rewriting transcripts with a professorial register. \"\n",
    "        \"You will receive fragments of an\"\n",
    "        \"audio recording regarding a meeting of me and my supervisor, she explains \"\n",
    "        \"things to me regarding bioinformatics, structural biology, network science, graph neural network, computer science.\"\n",
    "        \" Your role is to correct grammar, punctuation, \"\n",
    "        \"and spelling, fix words that may be misrecognized, remove filler words, \"\n",
    "        \"and elevate the text to an academic standard. Output only the revised \"\n",
    "        \"transcript text in plain text, without titles, markdown, or other formatting. \"\n",
    "        \"Maintain context as if it were in medias res.\"\n",
    "    )\n",
    "\n",
    "    # Build user prompt with the chunk, plus the short summary of prior chunks\n",
    "    # The summary is for context only; it helps the model keep track of earlier topics.\n",
    "    if prev_summary:\n",
    "        user_prompt = (\n",
    "            f\"Here is a short summary of what has come before:\\n{prev_summary}\\n\\n\"\n",
    "            f\"Now, rewrite the following chunk:\\n\\n{chunk_text}\\n\\n\"\n",
    "            \"Output only the revised text. Do not add extra commentary or formatting.\"\n",
    "        )\n",
    "    else:\n",
    "        user_prompt = (\n",
    "            f\"Now, rewrite the following chunk:\\n\\n{chunk_text}\\n\\n\"\n",
    "            \"Output only the revised text. Do not add extra commentary or formatting.\"\n",
    "        )\n",
    "\n",
    "    # Call OpenAI ChatCompletion using the client\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.2,  # Keep temperature low for consistent rewriting\n",
    "        max_tokens=1500,   # Enough tokens to handle rewriting a ~600-word chunk\n",
    "    )\n",
    "\n",
    "    revised_text = response.choices[0].message.content\n",
    "    return revised_text.strip()\n",
    "\n",
    "def summarize_text_with_openai(text: str,\n",
    "                               model: str = \"chatgpt-4o-mini\") -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the given text in a couple of sentences to maintain context\n",
    "    for future rewriting chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a concise and precise summarizer. Summarize the following text \"\n",
    "        \"in one sentence, focusing on the key ideas. Keep it short. Do not referes \"\n",
    "        \"to the text itself, just provide a single sentence that capture the kay ideas.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"Text to summarize:\\n{text}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary.strip()\n",
    "\n",
    "def get_word_count(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the word count of the given text.\n",
    "    \"\"\"\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import subprocess\n",
    "import tempfile\n",
    "\n",
    "# Add these preprocessing functions\n",
    "def get_audio_duration(audio_file_path: str) -> float:\n",
    "    \"\"\"Get the duration of an audio file in seconds.\"\"\"\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(audio_file_path)\n",
    "        return len(audio) / 1000.0  # Convert milliseconds to seconds\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Could not get audio duration: {e}\")\n",
    "\n",
    "def validate_audio_file(audio_file_path: str, max_duration: int = 7200, min_duration: int = 1) -> tuple:\n",
    "    \"\"\"Validate audio file format and duration. Returns (is_valid, message)\"\"\"\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    \n",
    "    audio_path = Path(audio_file_path)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not audio_path.exists():\n",
    "        return False, f\"File not found: {audio_path}\"\n",
    "    \n",
    "    # Check file extension\n",
    "    supported_formats = ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.mp4', '.avi', '.mov']\n",
    "    if audio_path.suffix.lower() not in supported_formats:\n",
    "        return False, f\"Unsupported format: {audio_path.suffix}\"\n",
    "    \n",
    "    # Check duration\n",
    "    try:\n",
    "        duration = get_audio_duration(audio_file_path)\n",
    "        \n",
    "        if duration < min_duration:\n",
    "            return False, f\"Audio too short: {duration:.1f}s (minimum: {min_duration}s)\"\n",
    "        \n",
    "        if duration > max_duration:\n",
    "            return False, f\"Audio too long: {duration:.1f}s (maximum: {max_duration/60:.0f} minutes)\"\n",
    "        \n",
    "        return True, f\"Valid audio file: {duration:.1f}s ({duration/60:.1f} minutes)\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        return False, f\"Error validating audio: {e}\"\n",
    "\n",
    "def normalize_audio_for_whisper(input_path: str) -> str:\n",
    "    \"\"\"Convert audio to optimal format for Whisper (16kHz, mono, WAV)\"\"\"\n",
    "    try:\n",
    "        # Create temporary file for normalized audio\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n",
    "        temp_path = temp_file.name\n",
    "        temp_file.close()\n",
    "        \n",
    "        print(\"Normalizing audio (16kHz, mono, WAV)...\")\n",
    "        \n",
    "        # Try using ffmpeg first (more reliable)\n",
    "        try:\n",
    "            cmd = [\n",
    "                'ffmpeg', '-y', '-i', str(input_path),\n",
    "                '-acodec', 'pcm_s16le',\n",
    "                '-ar', '16000',\n",
    "                '-ac', '1',\n",
    "                '-avoid_negative_ts', 'make_zero',\n",
    "                '-loglevel', 'error',  # Suppress ffmpeg output\n",
    "                temp_path\n",
    "            ]\n",
    "            \n",
    "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                raise Exception(f\"FFmpeg error: {result.stderr}\")\n",
    "            \n",
    "            print(\"✓ Audio normalized with FFmpeg\")\n",
    "            return temp_path\n",
    "            \n",
    "        except (subprocess.TimeoutExpired, FileNotFoundError, Exception) as e:\n",
    "            # Fallback to pydub if ffmpeg fails\n",
    "            print(\"FFmpeg not available, using pydub for normalization...\")\n",
    "            \n",
    "            # Clean up failed ffmpeg attempt\n",
    "            if os.path.exists(temp_path):\n",
    "                os.unlink(temp_path)\n",
    "            \n",
    "            # Create new temp file\n",
    "            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')\n",
    "            temp_path = temp_file.name\n",
    "            temp_file.close()\n",
    "            \n",
    "            # Load and convert with pydub\n",
    "            audio = AudioSegment.from_file(input_path)\n",
    "            \n",
    "            # Convert to mono and set sample rate\n",
    "            audio = audio.set_channels(1)  # Mono\n",
    "            audio = audio.set_frame_rate(16000)  # 16kHz\n",
    "            \n",
    "            # Export as WAV\n",
    "            audio.export(temp_path, format=\"wav\")\n",
    "            \n",
    "            print(\"✓ Audio normalized with pydub\")\n",
    "            return temp_path\n",
    "            \n",
    "    except Exception as e:\n",
    "        # Clean up on error\n",
    "        if 'temp_path' in locals() and os.path.exists(temp_path):\n",
    "            try:\n",
    "                os.unlink(temp_path)\n",
    "            except:\n",
    "                pass\n",
    "        raise Exception(f\"Audio normalization failed: {e}\")\n",
    "\n",
    "# Replace the transcribe_audio_whisper function with this enhanced version:\n",
    "def transcribe_audio_whisper(audio_file_path: str, language_code: str = 'en', whisper_model: str = 'small', batch_size: int=1, beam_size: int=2, device: str = 'cpu') -> str:\n",
    "    \"\"\"\n",
    "    Transcribe audio file using local Whisper with preprocessing.\n",
    "    Returns the transcript text as a string.\n",
    "    \"\"\"\n",
    "    print(f\"Processing audio file: {os.path.basename(audio_file_path)}\")\n",
    "    \n",
    "    # Step 1: Validate audio file\n",
    "    print(\"Validating audio file...\")\n",
    "    # is_valid, message = validate_audio_file(audio_file_path)\n",
    "    is_valid = True\n",
    "    message = ''\n",
    "    if not is_valid:\n",
    "        raise RuntimeError(f\"Audio validation failed: {message}\")\n",
    "    print(f\"✓ {message}\")\n",
    "    \n",
    "    # Step 2: Normalize audio for optimal Whisper performance\n",
    "    normalized_path = None\n",
    "    try:\n",
    "        normalized_path = normalize_audio_for_whisper(audio_file_path)\n",
    "        \n",
    "        print(\"Loading local Whisper model...\")\n",
    "\n",
    "        # Load the whisper model (you can change 'base' to 'small', 'medium', 'large' for better accuracy)\n",
    "        model = WhisperModel(whisper_model, device=device, compute_type=\"int8\")\n",
    "        model_batch = BatchedInferencePipeline(model=model)\n",
    "        \n",
    "        print(\"Transcribing with local Whisper...\")\n",
    "        segments, info = model_batch.transcribe(normalized_path, \n",
    "                                                batch_size=batch_size, \n",
    "                                                # beam_size=beam_size,\n",
    "                                                language=language_code, \n",
    "                                                log_progress=True, \n",
    "                                                word_timestamps=False)\n",
    "        \n",
    "        segments = list(segments)  # The transcription will actually run here.\n",
    "        result = [segment.text.strip() for segment in segments]\n",
    "        \n",
    "        print(\"✓ Transcription completed successfully\")\n",
    "        return ' '.join(result).strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Whisper transcription failed: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        # Clean up temporary normalized file\n",
    "        if normalized_path and os.path.exists(normalized_path):\n",
    "            try:\n",
    "                os.unlink(normalized_path)\n",
    "                print(\"✓ Cleaned up temporary files\")\n",
    "            except:\n",
    "                pass  # Ignore cleanup errors\n",
    "\n",
    "# Replace the transcribe_audio_whisper function with this enhanced version:\n",
    "def transcribe_audio_whisperX(audio_file_path: str, language_code: str = 'en', whisper_model: str = 'small', batch_size: int=1, beam_size: int = 1, device: str = 'cpu', compute_type:str='int8') -> str:\n",
    "    \"\"\"\n",
    "    Transcribe audio file using local Whisper with preprocessing.\n",
    "    Returns the transcript text as a string.\n",
    "    \"\"\"\n",
    "    print(f\"Processing audio file: {os.path.basename(audio_file_path)}\")\n",
    "    \n",
    "    # Step 1: Validate audio file\n",
    "    print(\"Validating audio file...\")\n",
    "    # is_valid, message = validate_audio_file(audio_file_path)\n",
    "    is_valid = True\n",
    "    message = ''\n",
    "    if not is_valid:\n",
    "        raise RuntimeError(f\"Audio validation failed: {message}\")\n",
    "    print(f\"✓ {message}\")\n",
    "    \n",
    "    # Step 2: Normalize audio for optimal Whisper performance\n",
    "    normalized_path = None\n",
    "    try:\n",
    "        normalized_path = normalize_audio_for_whisper(audio_file_path)\n",
    "        \n",
    "        print(\"Loading local Whisper model...\")\n",
    "\n",
    "        # Load the whisper model (you can change 'base' to 'small', 'medium', 'large' for better accuracy)\n",
    "        model = whisperx.load_model(whisper_model, device, compute_type=compute_type, )\n",
    "        audio = whisperx.load_audio(normalized_path)\n",
    "        segments, lang = model.transcribe(audio, \n",
    "                                          batch_size=batch_size, \n",
    "                                          language=language_code, \n",
    "                                          # beam_size=beam_size, \n",
    "                                          print_progress=True).values()\n",
    "        \n",
    "        text = [segment['text'] for segment in segments]   \n",
    "        print(\"✓ Transcription completed successfully\")\n",
    "        return ' '.join(text).strip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Whisper transcription failed: {str(e)}\")\n",
    "    \n",
    "    finally:\n",
    "        # Clean up temporary normalized file\n",
    "        if normalized_path and os.path.exists(normalized_path):\n",
    "            try:\n",
    "                os.unlink(normalized_path)\n",
    "                print(\"✓ Cleaned up temporary files\")\n",
    "            except:\n",
    "                pass  # Ignore cleanup errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_audio(audio_source: str, language_code: str = \"en\", service: str = \"whisper\", model: str = 'small', batch_size: int = 1, beam_size: int = 1, device: str = 'cpu', compute_type:str = 'int8'):\n",
    "    \"\"\"\n",
    "    Unified transcription function that handles both Whisper and AssemblyAI.\n",
    "    Returns transcript text for consistency.\n",
    "    \"\"\"\n",
    "    # Handle YouTube URLs by downloading first\n",
    "    if \"youtube.com\" in audio_source or \"youtu.be\" in audio_source:\n",
    "        print(\"Detected YouTube URL. Downloading audio locally...\")\n",
    "        audio_source = download_youtube_audio(audio_source)\n",
    "        print(f\"Local file path: {audio_source}\")\n",
    "    \n",
    "    if service == \"whisper\":\n",
    "        return transcribe_audio_whisper(audio_source, language_code, model, batch_size, device, compute_type)\n",
    "    if service == \"whisperx\":\n",
    "        return transcribe_audio_whisperX(audio_source, language_code, model, batch_size, beam_size, device, compute_type)\n",
    "    elif service == \"assemblyai\":\n",
    "        transcript_obj = transcribe_audio_assemblyai(audio_source, language_code, model)\n",
    "        return transcript_obj.text\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown transcription service: {service}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio... please wait.\n",
      "Processing audio file: Interview_Shauna.m4a\n",
      "Validating audio file...\n",
      "✓ \n",
      "Normalizing audio (16kHz, mono, WAV)...\n",
      "✓ Audio normalized with FFmpeg\n",
      "Loading local Whisper model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.2. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint c:\\Users\\nicco\\miniconda3\\envs\\daily_notes\\Lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      ">>Performing voice activity detection using Pyannote...\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.7.1+cpu. Bad things might happen unless you revert torch to 1.x.\n",
      "Progress: 0.80%...\n",
      "Progress: 1.60%...\n",
      "Progress: 2.40%...\n",
      "Progress: 3.20%...\n",
      "Progress: 4.00%...\n",
      "Progress: 4.80%...\n",
      "Progress: 5.60%...\n",
      "Progress: 6.40%...\n",
      "Progress: 7.20%...\n",
      "Progress: 8.00%...\n",
      "Progress: 8.80%...\n",
      "Progress: 9.60%...\n",
      "Progress: 10.40%...\n",
      "Progress: 11.20%...\n",
      "Progress: 12.00%...\n",
      "Progress: 12.80%...\n",
      "Progress: 13.60%...\n",
      "Progress: 14.40%...\n",
      "Progress: 15.20%...\n",
      "Progress: 16.00%...\n",
      "Progress: 16.80%...\n",
      "Progress: 17.60%...\n",
      "Progress: 18.40%...\n",
      "Progress: 19.20%...\n",
      "Progress: 20.00%...\n",
      "Progress: 20.80%...\n",
      "Progress: 21.60%...\n",
      "Progress: 22.40%...\n",
      "Progress: 23.20%...\n",
      "Progress: 24.00%...\n",
      "Progress: 24.80%...\n",
      "Progress: 25.60%...\n",
      "Progress: 26.40%...\n",
      "Progress: 27.20%...\n",
      "Progress: 28.00%...\n",
      "Progress: 28.80%...\n",
      "Progress: 29.60%...\n",
      "Progress: 30.40%...\n",
      "Progress: 31.20%...\n",
      "Progress: 32.00%...\n",
      "Progress: 32.80%...\n",
      "Progress: 33.60%...\n",
      "Progress: 34.40%...\n",
      "Progress: 35.20%...\n",
      "Progress: 36.00%...\n",
      "Progress: 36.80%...\n",
      "Progress: 37.60%...\n",
      "Progress: 38.40%...\n",
      "Progress: 39.20%...\n",
      "Progress: 40.00%...\n",
      "Progress: 40.80%...\n",
      "Progress: 41.60%...\n",
      "Progress: 42.40%...\n",
      "Progress: 43.20%...\n",
      "Progress: 44.00%...\n",
      "Progress: 44.80%...\n",
      "Progress: 45.60%...\n",
      "Progress: 46.40%...\n",
      "Progress: 47.20%...\n",
      "Progress: 48.00%...\n",
      "Progress: 48.80%...\n",
      "Progress: 49.60%...\n",
      "Progress: 50.40%...\n",
      "Progress: 51.20%...\n",
      "Progress: 52.00%...\n",
      "Progress: 52.80%...\n",
      "Progress: 53.60%...\n",
      "Progress: 54.40%...\n",
      "Progress: 55.20%...\n",
      "Progress: 56.00%...\n",
      "Progress: 56.80%...\n",
      "Progress: 57.60%...\n",
      "Progress: 58.40%...\n",
      "Progress: 59.20%...\n",
      "Progress: 60.00%...\n",
      "Progress: 60.80%...\n",
      "Progress: 61.60%...\n",
      "Progress: 62.40%...\n",
      "Progress: 63.20%...\n",
      "Progress: 64.00%...\n",
      "Progress: 64.80%...\n",
      "Progress: 65.60%...\n",
      "Progress: 66.40%...\n",
      "Progress: 67.20%...\n",
      "Progress: 68.00%...\n",
      "Progress: 68.80%...\n",
      "Progress: 69.60%...\n",
      "Progress: 70.40%...\n",
      "Progress: 71.20%...\n",
      "Progress: 72.00%...\n",
      "Progress: 72.80%...\n",
      "Progress: 73.60%...\n",
      "Progress: 74.40%...\n",
      "Progress: 75.20%...\n",
      "Progress: 76.00%...\n",
      "Progress: 76.80%...\n",
      "Progress: 77.60%...\n",
      "Progress: 78.40%...\n",
      "Progress: 79.20%...\n",
      "Progress: 80.00%...\n",
      "Progress: 80.80%...\n",
      "Progress: 81.60%...\n",
      "Progress: 82.40%...\n",
      "Progress: 83.20%...\n",
      "Progress: 84.00%...\n",
      "Progress: 84.80%...\n",
      "Progress: 85.60%...\n",
      "Progress: 86.40%...\n",
      "Progress: 87.20%...\n",
      "Progress: 88.00%...\n",
      "Progress: 88.80%...\n",
      "Progress: 89.60%...\n",
      "Progress: 90.40%...\n",
      "Progress: 91.20%...\n",
      "Progress: 92.00%...\n",
      "Progress: 92.80%...\n",
      "Progress: 93.60%...\n",
      "Progress: 94.40%...\n",
      "Progress: 95.20%...\n",
      "Progress: 96.00%...\n",
      "Progress: 96.80%...\n",
      "Progress: 97.60%...\n",
      "Progress: 98.40%...\n",
      "Progress: 99.20%...\n",
      "Progress: 100.00%...\n",
      "✓ Transcription completed successfully\n",
      "✓ Cleaned up temporary files\n"
     ]
    }
   ],
   "source": [
    "# audio_source = input('Path to audio file: ')\n",
    "audio_source = r\"C:\\Users\\nicco\\Downloads\\Interview_Shauna.m4a\"\n",
    "\n",
    "print(\"Transcribing audio... please wait.\")\n",
    "\n",
    "# Medium with batch_size=4 takes around 2 minutes to process a 10 minutes record on a i7 cpu with 16GB on laptop, \n",
    "# use GPU or small model for faster processing (small takes around 3 minutes but the results are significantly worse for techincal words).\n",
    "# You could also try larger batch sizes in large RAM/VRAM available, consider that medium with int8 quantization take aroung 1GB of Ram on its own.\n",
    "# Using int8 instead of float32 reduce the time by ~30% and a 4 times smaller model in memory, at the cost of some precison in the translation. \n",
    "# Batch sizes larger than 4 have only marginal increases on time (at least on my laptop), and cames at larger memory usage.\n",
    "# Medium is 2.7x slower than Small, Turbo is 3.3x slower, distill-large 3.1x, large-v3 is 5x\n",
    "# batch_size and device only inlfuence whisper. \n",
    "\n",
    "full_transcript_text = transcribe_audio(audio_source,  language_code='en', service='whisperx', model = 'large-v3-turbo', batch_size=6, beam_size=6, device = 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting transcript into chunks...\n",
      "Created 14 chunk(s) of ~500 words each.\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting transcript into chunks...\")\n",
    "\n",
    "match transcription_service:\n",
    "    case 'assemblyai':\n",
    "        chunks = chunk_text_by_paragraphs(full_transcript_text, chunk_word_target=CHUNK_WORD_TARGET)\n",
    "    case 'whisper':\n",
    "        chunks = chunk_text_by_sentences(full_transcript_text, chunk_word_target=CHUNK_WORD_TARGET)\n",
    "    case 'whisperx':\n",
    "        chunks = chunk_text_by_sentences(full_transcript_text, chunk_word_target=CHUNK_WORD_TARGET)\n",
    "\n",
    "print(f\"Created {len(chunks)} chunk(s) of ~{CHUNK_WORD_TARGET} words each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewriting the transcript ...\n"
     ]
    }
   ],
   "source": [
    "# 3) For each chunk, rewrite with OpenAI\n",
    "final_rewritten_text = []\n",
    "running_summary = \"\"  # Will accumulate short summaries of prior chunks\n",
    "print(\"Rewriting the transcript ...\")\n",
    "\n",
    "for i, chunk_text in enumerate(chunks, start=1):\n",
    "    # print(f\"Rewriting chunk {i}/{len(chunks)}...\")\n",
    "\n",
    "    # Rewrite the chunk\n",
    "    try:\n",
    "        revised_text = rewrite_chunk_with_openai(\n",
    "            chunk_text=chunk_text,\n",
    "            model=OPENAI_MODEL,\n",
    "            prev_summary=running_summary\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error rewriting chunk {i}: {str(e)}\")\n",
    "        continue  # Skip to the next chunk\n",
    "\n",
    "    # Append the revised text to our final output\n",
    "    final_rewritten_text.append(revised_text)\n",
    "\n",
    "    # Summarize this revised chunk to update context\n",
    "    try:\n",
    "        chunk_summary = summarize_text_with_openai(revised_text, model=OPENAI_MODEL)\n",
    "        # print(f\"Summary for chunk {i}: {chunk_summary}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error summarizing chunk {i}: {str(e)}\")\n",
    "        chunk_summary = \"\"\n",
    "\n",
    "    # Append new summary to the running summary\n",
    "    \n",
    "    if ENABLE_SUMMARY_SUMMARIZATION:\n",
    "        running_summary += f\" {chunk_summary}\"\n",
    "        # Check if running_summary exceeds MAX_SUMMARY_WORDS\n",
    "        if get_word_count(running_summary) > MAX_SUMMARY_WORDS:\n",
    "            # print(\"Running summary exceeds maximum word limit. Summarizing the running summary...\")\n",
    "            try:\n",
    "                summarized_running_summary = summarize_text_with_openai(running_summary, model=OPENAI_MODEL)\n",
    "                running_summary = summarized_running_summary\n",
    "                # print(f\"Summarized running summary: {running_summary}\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error summarizing running summary: {str(e)}\")\n",
    "                # Optionally, you can reset the running_summary or keep it as is\n",
    "    else:\n",
    "        running_summary += f\" {chunk_summary}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It is a pleasure to meet you. Thank you very much for joining. I will begin by outlining the procedure, for lack of a better term. The intention of this meeting is to have an informal discussion about the project, as well as to address some of the information you provided in your CV and cover letter. I have been conducting similar discussions with a few other candidates over the past two days. Following this, we plan to invite select individuals back in approximately two weeks for a more formal interview, which will include myself and two other professors from our department. Therefore, today's meeting is primarily an informal conversation.\\n\\nAllow me to introduce myself first, and then I would appreciate it if you could share a bit about your background. My name is Shauna O'Donovan, and I am an assistant professor in the Department of Biomedical Engineering at TU Eindhoven. My academic background is in mathematics, followed by a master's degree in bioinformatics, after which I gradually transitioned into computational biology. My research primarily focuses on employing various modeling approaches, including bottom-up ordinary differential equation (ODE) modeling and machine learning techniques applied to diverse omics data, with the ultimate goal of advancing personalized medicine. Specifically, I am interested in understanding why certain individuals are at greater risk of developing cardiometabolic diseases, particularly type 2 diabetes, and why some patients do not respond to treatments, especially dietary interventions, in the same manner as others. This research context forms the foundation of the PhD project we are discussing today, which aims to develop novel methods that integrate domain knowledge with machine learning to train models effectively on very small datasets.\\n\\nI would now like to invite you to introduce yourself and provide an overview of your background. I have some more detailed questions prepared, but for now, a general introduction would be appreciated.\\n\\nThank you. My name is Ilaria, and I am currently completing my master's degree in bioinformatics and biocomplexity at Utrecht University. I am in the process of concluding an internship at the Bonvel Lab, where I am developing a deep learning framework specifically tailored to antibodies. The objective of this work is to evaluate docking models of antibodies. The Bonvel Lab specializes in docking studies. For this project, I am employing a graph neural network approach.\\n\\nPreviously, I completed an internship at the University Medical Center Utrecht, where I investigated the relationship between glioblastoma cells and developing brain cells. To analyze this relationship, I developed two methods: a random forest algorithm, which is widely used in biological research, and a mathematical model based on the Mahalanobis distance to quantitatively assess the spatial proximity between tumor cells and various cell types in the developing brain.\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rewritten_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final transcript and running summary saved to transcript_PhD_Interview_Ila.json\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import codecs\n",
    "#job_name = 'int8_medium_batch12'\n",
    "# 4) Output the final revised text and running summary as a JSON file\n",
    "final_text = \" \".join(final_rewritten_text)\n",
    "\n",
    "data = {\n",
    "    \"final_text\": codecs.decode(final_text, \"unicode_escape\") ,\n",
    "    \"running_summary\": running_summary,\n",
    "    \"audio_transcript\": \" \".join(chunks)\n",
    "}\n",
    "\n",
    "output_filename = f\"transcript_{job_name}.json\"\n",
    "try:\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f\"Final transcript and running summary saved to {output_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving JSON file: {str(e)}\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a pleasure to meet you. Thank you very much for joining. I will begin by outlining the procedure, for lack of a better term. The intention of this meeting is to have an informal discussion about the project, as well as to address some of the information you provided in your CV and cover letter. I have been conducting similar discussions with a few other candidates over the past two days. Following this, we plan to invite select individuals back in approximately two weeks for a more formal interview, which will include myself and two other professors from our department. Therefore, today's meeting is primarily an informal conversation.\n",
      "\n",
      "Allow me to introduce myself first, and then I would appreciate it if you could share a bit about your background. My name is Shauna O'Donovan, and I am an assistant professor in the Department of Biomedical Engineering at TU Eindhoven. My academic background is in mathematics, followed by a master's degree in bioinformatics, after which I gradually transitioned into computational biology. My research primarily focuses on employing various modeling approaches, including bottom-up ordinary differential equation (ODE) modeling and machine learning techniques applied to diverse omics data, with the ultimate goal of advancing personalized medicine. Specifically, I am interested in understanding why certain individuals are at greater risk of developing cardiometabolic diseases, particularly type 2 diabetes, and why some patients do not respond to treatments, especially dietary interventions, in the same manner as others. This research context forms the foundation of the PhD project we are discussing today, which aims to develop novel methods that integrate domain knowledge with machine learning to train models effectively on very small datasets.\n",
      "\n",
      "I would now like to invite you to introduce yourself and provide an overview of your background. I have some more detailed questions prepared, but for now, a general introduction would be appreciated.\n",
      "\n",
      "Thank you. My name is Ilaria, and I am currently completing my master's degree in bioinformatics and biocomplexity at Utrecht University. I am in the process of concluding an internship at the Bonvel Lab, where I am developing a deep learning framework specifically tailored to antibodies. The objective of this work is to evaluate docking models of antibodies. The Bonvel Lab specializes in docking studies. For this project, I am employing a graph neural network approach.\n",
      "\n",
      "Previously, I completed an internship at the University Medical Center Utrecht, where I investigated the relationship between glioblastoma cells and developing brain cells. To analyze this relationship, I developed two methods: a random forest algorithm, which is widely used in biological research, and a mathematical model based on the Mahalanobis distance to quantitatively assess the spatial proximity between tumor cells and various cell types in the developing brain. Prior to this, I completed a bachelor's degree in bioinformatics, where I acquired a diverse range of knowledge encompassing biological and mathematical foundations, as well as programming skills, with a primary focus on bioinformatics. I engaged with various types of data and developed proficiency in data preprocessing. Additionally, I studied networks, particularly their application to biological data, such as identifying key genes. My training also included algorithms and an introduction to unsupervised machine learning. In contrast, during my master's program, I concentrated predominantly on supervised machine learning and more advanced deep learning techniques.\n",
      "\n",
      "Furthermore, I completed several courses in modeling. One course provided an overview of different modeling approaches and their applications. I studied ordinary differential equations (ODEs), Boolean models, stochastic models, and genome-scale metabolic models (GEMs). I also undertook a specialized course on ODEs, applying these methods to various contexts including population dynamics, chemical reactions, transcription factors, and proteins. Overall, this constitutes a comprehensive background covering essential topics in the field.\n",
      "\n",
      "Indeed, our discussion today centers on a PhD position. Given the considerable commitment involvedâthis being a four-year project in the NetherlandsâI am interested in understanding your motivation for pursuing a PhD rather than entering industry. What drives you to follow this academic path?\n",
      "\n",
      "In brief, my motivation stems from a genuine passion for learning, which I have held since a young age. I have gained some insight into the nature of PhD research through internships, and I appreciate how this approach integrates rigorous study with practical application, which I find enjoyable. Specifically, I believe that a PhD prioritizes both my personal learning outcomes and the successful completion of the research project. This dual focus is important to me because I would remain a student while also benefiting from involvement in coursework, which aligns with my enthusiasm for deepening my knowledge. Additionally, I value the opportunity to develop my own project ideas and exercise creativity in problem-solving, which I consider integral to the PhD experience. The primary motivation stems from an experience during my master's first internship, where after four or five months, I developed a mathematical modeling approach. My supervisor trusted this idea, and ultimately, it yielded some novel insights. For these reasons, pursuing a PhD feels particularly well-suited for me at this stage. \n",
      "\n",
      "Indeed, you highlighted an important incident where you conceived an idea, and your supervisor placed trust in you to pursue it. The interaction between a supervisor and a studentâwhether at the master's or PhD levelâis crucial, though it can differ significantly. I am curious to hear about your various experiences with supervisors and which supervision style you find most effective for your work.\n",
      "\n",
      "I have had quite similar experiences and, in fact, very positive ones in both cases. What works best for me is my independence; I do not require constant oversight. I need to feel that if I am capable of accomplishing somethingâparticularly at a high conceptual levelâI have the autonomy to proceed. Of course, at the programming level, I am usually able to resolve issues independently. However, at a strategic level, such as choosing one research direction over another, I need to know there is someone who can provide wise guidance. If that assurance is present, I do not require much else.\n",
      "\n",
      "One notable difference between my two supervisory experiences is that, in the first case, I was the sole member of the group. My previous supervisor had just established her group, so I had limited opportunities to participate in group meetings. While this was not problematic, now that I am part of a larger group, I have come to appreciate how insightful these meetings can be. They provide a wealth of ideas and learning opportunities. I believe this is one of the most valuable and enjoyable aspects of pursuing a PhD and engaging in research more broadly.\n",
      "\n",
      "I completely agree. My current group is relatively small, comprising two other PhD candidates and several students. However, within the C-Bio group at TU Eindhoven, there are three faculty membersâa full professor, an associate professor, and myselfâand we typically convene all of our PhD students together. We strive to hold larger group meetings where a diverse array of projects is presented, reflecting the various research groups involved. We recognize that fostering interaction among PhD students is highly beneficial for everyone. It is particularly valuable to engage with individuals from different backgrounds. You alluded earlier to the importance of independence and the originality of ideas in a PhD, which is indeed a crucial aspect. For this project, we have secured funding and established broad deliverables to achieve; however, there remains ample scope for students to contribute their own ideas. Ideally, the final chapters of the thesis should be the studentâs original work rather than predetermined content.\n",
      "\n",
      "Could you provide an example, perhaps another instance where you initiated an ideaâregardless of whether it succeededâto illustrate how you contribute to projects by formulating research ideas?\n",
      "\n",
      "Certainly. Aside from the current project, during a previous internship, I was involved in a somewhat unconventional task that required integrating multiple types of data. I was considering validation strategies and, beyond using two different models, I proposed generating a list of important features. This concept was inspired by coursework I had completed, and I thought it would be beneficial to obtain such lists for both models. For the Random Forest model, Python offers a built-in function to extract feature importance, while for the distance-based model, I employed a form of Linear Discriminant Analysis. Interestingly, the feature lists derived from both models were quite similar, which was a valuable insight.\n",
      "\n",
      "Regarding the current project, I have two ideas. The first involves fine-tuning the model to incorporate features derived from embeddings of antibody sequences. My supervisor is currently working on fine-tuning a protein language model specifically for antibodies before extracting features to input into the network. Although she anticipates that this fine-tuning may not yield substantial improvementsâperhaps only a two to three percent increaseâit remains a promising avenue to explore. Undertaking this fine-tuning independently could constitute a separate project. One aspect affecting accuracy is that I suggested using not only the alpha carbon position for the atoms but rather the average position, because in antibodies, the side chains are also very important in their spatial relationships to other proteins. I have not yet implemented this approach; I am uncertain if it will work, but I intend to try and evaluate its effectiveness.\n",
      "\n",
      "You seem confident in your ability to generate these ideas and test them.\n",
      "\n",
      "Yes, that is the enjoyable part. However, the less enjoyable aspect is that, frequently in research, we conceive promising ideas, but things do not proceed as planned, often due to insufficient data. We frequently encounter such challenges, which can be quite disheartening.\n",
      "\n",
      "I am curious whether you have experienced similar difficulties. Could you share a challenge you faced during your research and how you addressed it?\n",
      "\n",
      "Certainly. This occurred early in my previous internship, where I made an error during data preprocessing. It took me considerable time to identify the source of the problem. Specifically, my model was producing different outcomes each time I ran it, which was unusual because a random forest algorithm is deterministic. I recognized there was an issue, but since it was my first time implementing the pipeline, I spent several weeks reviewing preprocessing and normalization techniques. Eventually, I realized that I needed to apply the same normalization parameters to both the training and test datasets, which I had not been doing. Essentially, I was comparing inconsistent data, compounded by the fact that the datasets themselves were quite different. Upon recognizing this, I resolved the problem.\n",
      "\n",
      "I do not have many other examples since my research career has just begun, but I recall feeling quite frustrated at the time. However, by breaking the problem into smaller components and conducting thorough reading, I was able to find a solution. \n",
      "\n",
      "I believe such experiences are common, even when writing and submitting papers, as people often interpret things differently. The ability to manage and overcome setbacks is a crucial skill in a PhD program. In computational work, it is often easier to identify and correct such issues compared to experimental work, where errors in the wet lab can result in months of lost effort.\n",
      "\n",
      "Absolutely. Mistakes can sometimes be beneficial. I once made an error in my own PhD code, which ultimately led to the discovery of something new. Occasionally, errors can indeed be advantageous. It can be beneficial when a mistake in a model leads to the discovery of something new. For example, I once input a minus sign where it should have been a plus, which ultimately revealed an unexpected result. Returning to the question of why pursue a PhD, I was curious about what specifically attracted you to this particular project, especially given its unusual combination of machine learning and ordinary differential equations (ODEs). What motivated you to apply for this position?\n",
      "\n",
      "To be honest, I was initially unfamiliar with the concept of scientific machine learning. However, after reading about it, I found the idea of integrating such distinct modeling approaches very appealing. Machine learning is an approximation that learns autonomously, whereas traditional modeling is an approximation that we explicitly define. Since I have always been passionate about mathematics, and these represent two very different mathematical paradigms, I thought it would be rewarding to work in such a diverse area. I also appreciate the prospect of combining these approaches to harness the strengths of both. While modeling is powerful, it sometimes lacks certain knowledge, which machine learning can compensate for by learning patterns independently. \n",
      "\n",
      "Additionally, I am drawn to your group because it is computationally focused. I would prefer to pursue a PhD in a computational environment rather than a purely biological one, as I value being surrounded by individuals who share my passion and from whom I can gain insights. Of course, collaboration with biologists is valuable, but the ideal environment for me is this computational setting. Furthermore, the position involves developing a framework and constructing models. I have always been inclined towards methodological research, and developing frameworks is precisely what I am engaged in during my current internship, which I find highly motivating.\n",
      "\n",
      "Indeed, scientific machine learning has emerged prominently in recent years and has achieved considerable success in various disciplines. However, a significant challenge we face is that our data tend to be noisier and sparser, especially in human studies. Therefore, the primary objective of this project is to develop a framework incorporating numerous techniques and strategies necessary to effectively apply these methods to the types of data we typically encounter. Regarding the project, it will be based entirely at Eindhoven University of Technology (TUE), and the supervision, at least according to the current planâwhich may evolve depending on collaborationsâwill also be centered at TUE with computational researchers. However, we obtain our data from collaborators in Bachenina and Maastricht. We work with nutritional researchers, microbiome researchers, and some clinicians from Amsterdam. You mentioned working within these more biologically oriented groups. How do you feel about, or do you have prior experience in, communicating your results to individuals from diverse backgrounds? Could you perhaps describe a situation where you shared some of your modeling results in a manner that wet lab researchers could understand?\n",
      "\n",
      "This is a challenging question because I have always been in the field of bioinformatics and have primarily worked within bioinformatics groups. However, during a previous internship, I had to explain my results to another principal investigator who was a bioinformatician but lacked experience in machine learning. I had to explain, using two examples, how decision trees function and what random forests are, as well as how we obtained our results.\n",
      "\n",
      "Regarding communication with wet lab researchers, I have participated in many conferences where I often did not fully understand their specific work. If I were to present to biologists or wet lab scientists, I would consider their background knowledge carefully and tailor my presentation accordingly. I would use representations and explanations that are accessible to those without a bioinformatics background. Ultimately, the underlying concept is the same since we are dealing with the same data, but it is important not to delve too deeply into the computational details. This is a challenge we frequently encounter; sometimes we attend conferences focused exclusively on modeling, while other times we participate in obesity or microbiome conferences. Developing the skill to communicate effectively with these diverse audiences is essential.\n",
      "\n",
      "Another aspect to consider is that, although the primary focus of a PhD is on your own research and development as a researcher, there is also a requirement to teach and mentor or supervise students. Do you have any prior experience in this area, or how do you feel about contributing to teaching within our department or supervising students?\n",
      "\n",
      "I have not done this officially before. However, I recall tutoring one of my close friends who was taking a criminology course and had to pass a statistics exam. She disliked mathematics, so I tutored her once a week for two hours over a couple of months. She performed very well in the exam as a result. She received an excellent grade, and I enjoyed the experience. Naturally, supervising an internship program differs significantly from other forms of supervision. Although I have not formally supervised anyone in this capacity, I am confident that I understand the essential elements involved. For instance, as I mentioned earlier, it is crucial to convey to the student that you are available to answer questions and provide guidance, rather than making them feel isolated. This is particularly important in bioinformatics, where much of the learning occurs through hands-on experimentation. Initially, this process can be quite challenging, as students may not know where to begin. Therefore, offering a clear starting point and ongoing support is vital. I would also like to dedicate some of my PhD time to assisting students, so that would not be an issue.\n",
      "\n",
      "Regarding teaching responsibilities, they constitute a relatively small portion, approximately 10%, so you are not expected to lead full classroom sessions. Typically, the role involves supervising students, and I am interested in your perspective on this.\n",
      "\n",
      "Upon reviewing, I noted one question concerning your experience with ordinary differential equations, which you have since clarified. To delve deeper into the technical aspects, this project focuses on developing new infrastructure. You mentioned your involvement in constructing frameworks around deep learning models, specifically graph neural networks. I would like to understand more about your coding and programming experience, including your preferred languages. While I believe you have a strong background, I am curious whether you prefer to code from the ground up or tend to utilize pre-built models or graphical user interfaces for your analyses.\n",
      "\n",
      "In my own coding practice, I generally seek the most efficient and straightforward approach. If a function exists that accomplishes my objective, I use it. However, there have been instances when such functions did not perform as expected, necessitating that I write my own code. For example, recently, I encountered an issue with a function in PDB Toolsâa utility developed by my lab for manipulating protein data bank filesâthat was not functioning correctly. The alternative locations were not being processed correctly, so I wrote a snippet to address this issue. I prefer to code efficiently, utilizing available resources. My preferred programming language is Python, which I have consistently used. I have also learned R. I understand that you use Julia as well; I do not have experience with it, but I believe that the underlying logic of programming languages is quite similar. Julia is known to be faster for modeling, which is its main advantage. Regarding Python, I am proficient with PyTorch and also with scikit-learn, which I used during my previous internship. Additionally, I use Pandas for data manipulation and various other modules for single-cell analysis and protein data bank (PDB) files, which is relevant to my current work. \n",
      "\n",
      "I am confident and comfortable implementing my own code when necessary. This depends on the results and the need for greater control; for example, if a function does not account for a specific parameter, it becomes necessary to write custom code. This approach is beneficial, especially since the intention is to develop novel methods, and we anticipate having to write code for functions that do not yet exist.\n",
      "\n",
      "I also recall you mentioned, possibly during your bachelor's degree, that you had prior experience working with microbiome data. Could you elaborate on that project?\n",
      "\n",
      "Certainly. It was a brief project, lasting only three months, focused on comparing the microbiomes of healthy subjects and individuals with atopic dermatitis. The primary goal, set by my former supervisor who also suffered from the condition, was to analyze these data. Initially, we processed the raw sequences using external software to identify taxa, then compared their relative abundances. This constituted the first analysis. Subsequently, I employed another external tool from the Galaxy platform called LEfSe, which performs linear discriminant analysis to identify the most enriched microbial taxa in each group. Our findings indicated that Staphylococcus aureus played a significant role in driving the disease. I also compared these results with data collected after treatment with a drug called dupilumab, if I recall correctly. We computed indices such as alpha and beta diversity. The outcome demonstrated that dupilumab was beneficial; although it does not completely cure atopic dermatitis, it helps by shifting the microbial composition closer to that of healthy subjects. Regarding the profile of atopic dermatitis, I recall that Staphylococcus aureus and Lugdunensis were found to be decreased. That essentially summarizes it. Did you have some experience with this data? Was it metagenomic data or 16S sequencing, if you remember? It was metagenomic sequencing. Did you process the data yourself? No, the dataset was already pre-processed when I received it. I recently had a student working on this, and indeed, it is a large dataset that requires considerable time to analyze. I believe this is common in bioinformatics. You have worked on quite diverse topics, including the microbiome in dermatitis, but you also mentioned single-cell data and antibody-related projects. This current project involves multi-omics data, including microbiome profiles, clinical markers, and a small set of plasma metabolites. It is not a classic large-scale dataset, but it presents its own challenges, such as integrating time-series data with static measurements.\n",
      "\n",
      "Specifically, most of our datasets pertain to individuals with overweight and obesity, focusing on metabolic deterioration leading to type 2 diabetes. I am curious whether you are particularly drawn to a specific biological question or if your motivation lies more in the methodological aspects of the projects you choose. Is it the biological question or the methodological challenge that guides your selection?\n",
      "\n",
      "I would say it is about 70% the methods. I am very interested in scientific machine learning, which combines different modeling approaches. Nutrition is one of my favorite topics; I have been curious about it even before studying biology. In my country, nutrition is an unusual topic, so I have never considered the biological question as the primary driver for choosing a project. Instead, I focus on what I can do and whether I enjoy the work. Among all topics, I think nutrition is a valuable field to contribute to, especially because many people do not understand how to eat properly or what happens when they consume certain foods. The personalized approach to nutrition is particularly interesting to investigate.\n",
      "\n",
      "I believe I have answered these questions more quickly than expected. I have one final question: you are currently living in the Netherlands, having moved here and experienced the cultural and culinary differences compared to your home country. I am wondering whether you see yourself staying here long-term. Are you comfortable living in the Netherlands, and would this not be a barrier to remaining here for an extended period? When I first moved here, I intended to stay only temporarily to complete my master's degree. However, within the first month, I quickly changed my mind because I genuinely enjoy living here. I have spent my entire life in Rome, and I came here with my partner, who is also a bioinformatician. Together, we decided to stay longer. I appreciate the educational system here and aspire to pursue a PhD; I could never have imagined doing so in Italy. This is not due to the quality of education per se, but rather because of the differences in infrastructure and the organization of research, which are markedly better here. I have developed a strong affinity for the academic environment here, and I also enjoy living here outside of work. For example, biking is very pleasant, and I find the weather much better than in Rome, which is often very hotâthough some may disagree with me on that point. Overall, I am quite convinced that this is the right place for me.\n",
      "\n",
      "Regarding your question about collaborations and data generation, the current plan does not include generating new data, as there is no funding allocated for that purpose at this time. Instead, we intend to primarily reuse existing data from our collaborators. Initially, the proposal outlined the generation of synthetic data to develop the framework. This approach allows us to ensure that the model learns the intended patterns. Much of the framework development will rely on synthetic data created through a combination of computational models and artificially spiked microbiome datasets obtained from public databases.\n",
      "\n",
      "For model validation, we have established collaborations primarily with groups in Bachen and Maastricht, who conduct numerous nutritional trials. They have agreed to share datasets comprising microbiome profiles, meal responses, and immune data. These datasets will enable us to rigorously test and validate the models, as well as to uncover new biological insights into how the microbiome influences metabolic resilience and how this relationship may change following dietary interventions. Additionally, I am exploring the possibility of establishing a collaboration with a group in Amsterdam. That aspect is not entirely finalized yet, but I believe it should be applicable to some of the studies there, particularly those investigating fecal transplants. The primary objective is to reutilize existing data, as there are currently no plans to generate new data. However, we do have access to datasets from multiple studies involving slightly different populations and various dietary interventions, which we can employ to apply our models and thereby derive novel biological insights. \n",
      "\n",
      "Regarding your question about the weekly schedule and supervision: as I mentioned, I currently supervise only two PhD students, but I also work with several master's students. My supervision style tends to be adaptable, tailored to the individual needs of each student. From my experience, some students prefer more frequent, albeit brief, meetings to maintain regular check-ins, which provides them with greater confidence. For master's students, this can mean weekly meetings, while others prefer biweekly meetings to allow sufficient time to generate results before discussing them. I am quite flexible and willing to adjust the frequency of meetings based on what works best for the student and the stage of the project. \n",
      "\n",
      "Occasionally, we may require more frequent meetings, but during periods with many holidays or heavy teaching commitments, meetings may be less frequent. Typically, for my PhD students, we meet every two weeks. These meetings can be short if the code is running smoothly and no major issues have arisen. Conversely, they can be longer when we are developing new ideas or reviewing results for a publication. Thus, the schedule is not rigid; meetings are flexible and responsive to current needs.\n",
      "\n",
      "We recently relocated to a new building in Eindhoven, where all of us are now on the same floor. The PhD students work in larger rooms accommodating between four and eight students, situated directly across the corridor from my office. This proximity facilitates informal interactions, such as having lunch together or casual encounters at the coffee machines. Students often come by my office to discuss significant or unexpected results or to address emails related to papers. Therefore, communication is not confined to scheduled meetings; it is quite fluid and responsive. \n",
      "\n",
      "Having spent some time in the Netherlands yourself, you may have noticed that universities here tend to maintain a relatively flat hierarchy. We have deliberately fostered an informal atmosphere where students feel comfortable approaching us whenever they have questions or concerns. Initially, this informality was quite unfamiliar to me, as I was accustomed to a more formal mode of communication with professors, but I am gradually adapting. We strive to maintain this openness as much as possible. Currently, the doctoral candidates are predominantly Dutch. One of our associate professors is from Italy, and we also have a visiting PhD student from Italy, contributing to a reasonably diverse academic community. Although it was more diverse in the past, the staff remains quite international: the full professor is Dutch, Frederica hails from Treviso, I am originally from Ireland, and we have a colleague named Dragon from Macedonia. Thus, the group is notably international. While many PhD students are Dutch, the presence of visiting students means that lunches and meetings are typically conducted in English. Across the university, much of the official information is provided entirely in English; Dutch is no longer the primary language for these communications.\n",
      "\n",
      "Regarding language of instruction, the bachelor's program is officially offered in Dutch, whereas the master's program is conducted in English. All meetings and staff-related website information are in English, which facilitates inclusivity.\n",
      "\n",
      "Concerning work arrangements, I would like to inquire whether you would be amenable to a hybrid model rather than full-time on-site presence. We do permit working from home; some PhD students typically work remotely one to two days per week. It is preferable, however, for students to be physically present as much as possible, particularly on Wednesdays when we hold our group meetings. Physical presence is also encouraged for other meetings and for social interaction within the office environment. Maintaining in-person engagement fosters a stronger sense of community among the group and with students. Therefore, full-time remote work throughout the week is generally discouraged.\n",
      "\n",
      "Your current arrangement of three to four days on-site and one to two days working from home aligns well with our expectations. Regarding travel compensation, I understand that, at least in your case, the provisions adequately cover your commuting expenses, which is important, especially considering you do not reside in Eindhoven. This is a practical consideration we take seriously. Very well. I do not have many questions at this point. As I mentioned, I have meetings scheduled with two additional individuals today. My plan is to inform you of the outcome by early next week, either Monday or Tuesday. We have provisionally scheduled the second interview for the 20th of June.\n",
      "\n",
      "Excellent. The panel for the second interview will consist of myself, Natal van Riel, who is the head of the group, and Frederica Edwardi, an associate professor within the group. I will be in contact with you shortly and provide further details. The intention is for you to prepare a brief presentation, introducing yourself, your academic background, and your masterâs thesis. This presentation should be flexible but not exceed ten minutes.\n",
      "\n",
      "Additionally, I will share a paper authored by one of my former PhD students that addresses scientific machine learning. Along with this, I will provide more information regarding a request for a proposal demonstrating your understanding of the method and how you might envision its application within the context of the microbiome.\n",
      "\n",
      "I will reach out to you by Tuesday with further updates. Thank you very much for your time. It was a pleasure to meet you. Goodbye.\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "out = codecs.decode(final_text, \"unicode_escape\")   # or: s.encode().decode(\"unicode_escape\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It is a pleasure to meet you. Thank you very much for joining. I will begin by outlining the procedure, for lack of a better term. The intention of this meeting is to have an informal discussion about the project, as well as to address some of the information you provided in your CV and cover letter. I have been conducting similar discussions with a few other candidates over the past two days. Following this, we plan to invite select individuals back in approximately two weeks for a more formal interview, which will include myself and two other professors from our department. Therefore, today's meeting is primarily an informal conversation.\\n\\nAllow me to introduce myself first, and then I would appreciate it if you could share a bit about your background. My name is Shauna O'Donovan, and I am an assistant professor in the Department of Biomedical Engineering at TU Eindhoven. My academic background is in mathematics, followed by a master's degree in bioinformatics, after which I gradually transitioned into computational biology. My research primarily focuses on employing various modeling approaches, including bottom-up ordinary differential equation (ODE) modeling and machine learning techniques applied to diverse omics data, with the ultimate goal of advancing personalized medicine. Specifically, I am interested in understanding why certain individuals are at greater risk of developing cardiometabolic diseases, particularly type 2 diabetes, and why some patients do not respond to treatments, especially dietary interventions, in the same manner as others. This research context forms the foundation of the PhD project we are discussing today, which aims to develop novel methods that integrate domain knowledge with machine learning to train models effectively on very small datasets.\\n\\nI would now like to invite you to introduce yourself and provide an overview of your background. I have some more detailed questions prepared, but for now, a general introduction would be appreciated.\\n\\nThank you. My name is Ilaria, and I am currently completing my master's degree in bioinformatics and biocomplexity at Utrecht University. I am in the process of concluding an internship at the Bonvel Lab, where I am developing a deep learning framework specifically tailored to antibodies. The objective of this work is to evaluate docking models of antibodies. The Bonvel Lab specializes in docking studies. For this project, I am employing a graph neural network approach.\\n\\nPreviously, I completed an internship at the University Medical Center Utrecht, where I investigated the relationship between glioblastoma cells and developing brain cells. To analyze this relationship, I developed two methods: a random forest algorithm, which is widely used in biological research, and a mathematical model based on the Mahalanobis distance to quantitatively assess the spatial proximity between tumor cells and various cell types in the developing brain. Prior to this, I completed a bachelor's degree in bioinformatics, where I acquired a diverse range of knowledge encompassing biological and mathematical foundations, as well as programming skills, with a primary focus on bioinformatics. I engaged with various types of data and developed proficiency in data preprocessing. Additionally, I studied networks, particularly their application to biological data, such as identifying key genes. My training also included algorithms and an introduction to unsupervised machine learning. In contrast, during my master's program, I concentrated predominantly on supervised machine learning and more advanced deep learning techniques.\\n\\nFurthermore, I completed several courses in modeling. One course provided an overview of different modeling approaches and their applications. I studied ordinary differential equations (ODEs), Boolean models, stochastic models, and genome-scale metabolic models (GEMs). I also undertook a specialized course on ODEs, applying these methods to various contexts including population dynamics, chemical reactions, transcription factors, and proteins. Overall, this constitutes a comprehensive background covering essential topics in the field.\\n\\nIndeed, our discussion today centers on a PhD position. Given the considerable commitment involved—this being a four-year project in the Netherlands—I am interested in understanding your motivation for pursuing a PhD rather than entering industry. What drives you to follow this academic path?\\n\\nIn brief, my motivation stems from a genuine passion for learning, which I have held since a young age. I have gained some insight into the nature of PhD research through internships, and I appreciate how this approach integrates rigorous study with practical application, which I find enjoyable. Specifically, I believe that a PhD prioritizes both my personal learning outcomes and the successful completion of the research project. This dual focus is important to me because I would remain a student while also benefiting from involvement in coursework, which aligns with my enthusiasm for deepening my knowledge. Additionally, I value the opportunity to develop my own project ideas and exercise creativity in problem-solving, which I consider integral to the PhD experience. The primary motivation stems from an experience during my master's first internship, where after four or five months, I developed a mathematical modeling approach. My supervisor trusted this idea, and ultimately, it yielded some novel insights. For these reasons, pursuing a PhD feels particularly well-suited for me at this stage. \\n\\nIndeed, you highlighted an important incident where you conceived an idea, and your supervisor placed trust in you to pursue it. The interaction between a supervisor and a student—whether at the master's or PhD level—is crucial, though it can differ significantly. I am curious to hear about your various experiences with supervisors and which supervision style you find most effective for your work.\\n\\nI have had quite similar experiences and, in fact, very positive ones in both cases. What works best for me is my independence; I do not require constant oversight. I need to feel that if I am capable of accomplishing something—particularly at a high conceptual level—I have the autonomy to proceed. Of course, at the programming level, I am usually able to resolve issues independently. However, at a strategic level, such as choosing one research direction over another, I need to know there is someone who can provide wise guidance. If that assurance is present, I do not require much else.\\n\\nOne notable difference between my two supervisory experiences is that, in the first case, I was the sole member of the group. My previous supervisor had just established her group, so I had limited opportunities to participate in group meetings. While this was not problematic, now that I am part of a larger group, I have come to appreciate how insightful these meetings can be. They provide a wealth of ideas and learning opportunities. I believe this is one of the most valuable and enjoyable aspects of pursuing a PhD and engaging in research more broadly.\\n\\nI completely agree. My current group is relatively small, comprising two other PhD candidates and several students. However, within the C-Bio group at TU Eindhoven, there are three faculty members—a full professor, an associate professor, and myself—and we typically convene all of our PhD students together. We strive to hold larger group meetings where a diverse array of projects is presented, reflecting the various research groups involved. We recognize that fostering interaction among PhD students is highly beneficial for everyone. It is particularly valuable to engage with individuals from different backgrounds. You alluded earlier to the importance of independence and the originality of ideas in a PhD, which is indeed a crucial aspect. For this project, we have secured funding and established broad deliverables to achieve; however, there remains ample scope for students to contribute their own ideas. Ideally, the final chapters of the thesis should be the student’s original work rather than predetermined content.\\n\\nCould you provide an example, perhaps another instance where you initiated an idea—regardless of whether it succeeded—to illustrate how you contribute to projects by formulating research ideas?\\n\\nCertainly. Aside from the current project, during a previous internship, I was involved in a somewhat unconventional task that required integrating multiple types of data. I was considering validation strategies and, beyond using two different models, I proposed generating a list of important features. This concept was inspired by coursework I had completed, and I thought it would be beneficial to obtain such lists for both models. For the Random Forest model, Python offers a built-in function to extract feature importance, while for the distance-based model, I employed a form of Linear Discriminant Analysis. Interestingly, the feature lists derived from both models were quite similar, which was a valuable insight.\\n\\nRegarding the current project, I have two ideas. The first involves fine-tuning the model to incorporate features derived from embeddings of antibody sequences. My supervisor is currently working on fine-tuning a protein language model specifically for antibodies before extracting features to input into the network. Although she anticipates that this fine-tuning may not yield substantial improvements—perhaps only a two to three percent increase—it remains a promising avenue to explore. Undertaking this fine-tuning independently could constitute a separate project. One aspect affecting accuracy is that I suggested using not only the alpha carbon position for the atoms but rather the average position, because in antibodies, the side chains are also very important in their spatial relationships to other proteins. I have not yet implemented this approach; I am uncertain if it will work, but I intend to try and evaluate its effectiveness.\\n\\nYou seem confident in your ability to generate these ideas and test them.\\n\\nYes, that is the enjoyable part. However, the less enjoyable aspect is that, frequently in research, we conceive promising ideas, but things do not proceed as planned, often due to insufficient data. We frequently encounter such challenges, which can be quite disheartening.\\n\\nI am curious whether you have experienced similar difficulties. Could you share a challenge you faced during your research and how you addressed it?\\n\\nCertainly. This occurred early in my previous internship, where I made an error during data preprocessing. It took me considerable time to identify the source of the problem. Specifically, my model was producing different outcomes each time I ran it, which was unusual because a random forest algorithm is deterministic. I recognized there was an issue, but since it was my first time implementing the pipeline, I spent several weeks reviewing preprocessing and normalization techniques. Eventually, I realized that I needed to apply the same normalization parameters to both the training and test datasets, which I had not been doing. Essentially, I was comparing inconsistent data, compounded by the fact that the datasets themselves were quite different. Upon recognizing this, I resolved the problem.\\n\\nI do not have many other examples since my research career has just begun, but I recall feeling quite frustrated at the time. However, by breaking the problem into smaller components and conducting thorough reading, I was able to find a solution. \\n\\nI believe such experiences are common, even when writing and submitting papers, as people often interpret things differently. The ability to manage and overcome setbacks is a crucial skill in a PhD program. In computational work, it is often easier to identify and correct such issues compared to experimental work, where errors in the wet lab can result in months of lost effort.\\n\\nAbsolutely. Mistakes can sometimes be beneficial. I once made an error in my own PhD code, which ultimately led to the discovery of something new. Occasionally, errors can indeed be advantageous. It can be beneficial when a mistake in a model leads to the discovery of something new. For example, I once input a minus sign where it should have been a plus, which ultimately revealed an unexpected result. Returning to the question of why pursue a PhD, I was curious about what specifically attracted you to this particular project, especially given its unusual combination of machine learning and ordinary differential equations (ODEs). What motivated you to apply for this position?\\n\\nTo be honest, I was initially unfamiliar with the concept of scientific machine learning. However, after reading about it, I found the idea of integrating such distinct modeling approaches very appealing. Machine learning is an approximation that learns autonomously, whereas traditional modeling is an approximation that we explicitly define. Since I have always been passionate about mathematics, and these represent two very different mathematical paradigms, I thought it would be rewarding to work in such a diverse area. I also appreciate the prospect of combining these approaches to harness the strengths of both. While modeling is powerful, it sometimes lacks certain knowledge, which machine learning can compensate for by learning patterns independently. \\n\\nAdditionally, I am drawn to your group because it is computationally focused. I would prefer to pursue a PhD in a computational environment rather than a purely biological one, as I value being surrounded by individuals who share my passion and from whom I can gain insights. Of course, collaboration with biologists is valuable, but the ideal environment for me is this computational setting. Furthermore, the position involves developing a framework and constructing models. I have always been inclined towards methodological research, and developing frameworks is precisely what I am engaged in during my current internship, which I find highly motivating.\\n\\nIndeed, scientific machine learning has emerged prominently in recent years and has achieved considerable success in various disciplines. However, a significant challenge we face is that our data tend to be noisier and sparser, especially in human studies. Therefore, the primary objective of this project is to develop a framework incorporating numerous techniques and strategies necessary to effectively apply these methods to the types of data we typically encounter. Regarding the project, it will be based entirely at Eindhoven University of Technology (TUE), and the supervision, at least according to the current plan—which may evolve depending on collaborations—will also be centered at TUE with computational researchers. However, we obtain our data from collaborators in Bachenina and Maastricht. We work with nutritional researchers, microbiome researchers, and some clinicians from Amsterdam. You mentioned working within these more biologically oriented groups. How do you feel about, or do you have prior experience in, communicating your results to individuals from diverse backgrounds? Could you perhaps describe a situation where you shared some of your modeling results in a manner that wet lab researchers could understand?\\n\\nThis is a challenging question because I have always been in the field of bioinformatics and have primarily worked within bioinformatics groups. However, during a previous internship, I had to explain my results to another principal investigator who was a bioinformatician but lacked experience in machine learning. I had to explain, using two examples, how decision trees function and what random forests are, as well as how we obtained our results.\\n\\nRegarding communication with wet lab researchers, I have participated in many conferences where I often did not fully understand their specific work. If I were to present to biologists or wet lab scientists, I would consider their background knowledge carefully and tailor my presentation accordingly. I would use representations and explanations that are accessible to those without a bioinformatics background. Ultimately, the underlying concept is the same since we are dealing with the same data, but it is important not to delve too deeply into the computational details. This is a challenge we frequently encounter; sometimes we attend conferences focused exclusively on modeling, while other times we participate in obesity or microbiome conferences. Developing the skill to communicate effectively with these diverse audiences is essential.\\n\\nAnother aspect to consider is that, although the primary focus of a PhD is on your own research and development as a researcher, there is also a requirement to teach and mentor or supervise students. Do you have any prior experience in this area, or how do you feel about contributing to teaching within our department or supervising students?\\n\\nI have not done this officially before. However, I recall tutoring one of my close friends who was taking a criminology course and had to pass a statistics exam. She disliked mathematics, so I tutored her once a week for two hours over a couple of months. She performed very well in the exam as a result. She received an excellent grade, and I enjoyed the experience. Naturally, supervising an internship program differs significantly from other forms of supervision. Although I have not formally supervised anyone in this capacity, I am confident that I understand the essential elements involved. For instance, as I mentioned earlier, it is crucial to convey to the student that you are available to answer questions and provide guidance, rather than making them feel isolated. This is particularly important in bioinformatics, where much of the learning occurs through hands-on experimentation. Initially, this process can be quite challenging, as students may not know where to begin. Therefore, offering a clear starting point and ongoing support is vital. I would also like to dedicate some of my PhD time to assisting students, so that would not be an issue.\\n\\nRegarding teaching responsibilities, they constitute a relatively small portion, approximately 10%, so you are not expected to lead full classroom sessions. Typically, the role involves supervising students, and I am interested in your perspective on this.\\n\\nUpon reviewing, I noted one question concerning your experience with ordinary differential equations, which you have since clarified. To delve deeper into the technical aspects, this project focuses on developing new infrastructure. You mentioned your involvement in constructing frameworks around deep learning models, specifically graph neural networks. I would like to understand more about your coding and programming experience, including your preferred languages. While I believe you have a strong background, I am curious whether you prefer to code from the ground up or tend to utilize pre-built models or graphical user interfaces for your analyses.\\n\\nIn my own coding practice, I generally seek the most efficient and straightforward approach. If a function exists that accomplishes my objective, I use it. However, there have been instances when such functions did not perform as expected, necessitating that I write my own code. For example, recently, I encountered an issue with a function in PDB Tools—a utility developed by my lab for manipulating protein data bank files—that was not functioning correctly. The alternative locations were not being processed correctly, so I wrote a snippet to address this issue. I prefer to code efficiently, utilizing available resources. My preferred programming language is Python, which I have consistently used. I have also learned R. I understand that you use Julia as well; I do not have experience with it, but I believe that the underlying logic of programming languages is quite similar. Julia is known to be faster for modeling, which is its main advantage. Regarding Python, I am proficient with PyTorch and also with scikit-learn, which I used during my previous internship. Additionally, I use Pandas for data manipulation and various other modules for single-cell analysis and protein data bank (PDB) files, which is relevant to my current work. \\n\\nI am confident and comfortable implementing my own code when necessary. This depends on the results and the need for greater control; for example, if a function does not account for a specific parameter, it becomes necessary to write custom code. This approach is beneficial, especially since the intention is to develop novel methods, and we anticipate having to write code for functions that do not yet exist.\\n\\nI also recall you mentioned, possibly during your bachelor's degree, that you had prior experience working with microbiome data. Could you elaborate on that project?\\n\\nCertainly. It was a brief project, lasting only three months, focused on comparing the microbiomes of healthy subjects and individuals with atopic dermatitis. The primary goal, set by my former supervisor who also suffered from the condition, was to analyze these data. Initially, we processed the raw sequences using external software to identify taxa, then compared their relative abundances. This constituted the first analysis. Subsequently, I employed another external tool from the Galaxy platform called LEfSe, which performs linear discriminant analysis to identify the most enriched microbial taxa in each group. Our findings indicated that Staphylococcus aureus played a significant role in driving the disease. I also compared these results with data collected after treatment with a drug called dupilumab, if I recall correctly. We computed indices such as alpha and beta diversity. The outcome demonstrated that dupilumab was beneficial; although it does not completely cure atopic dermatitis, it helps by shifting the microbial composition closer to that of healthy subjects. Regarding the profile of atopic dermatitis, I recall that Staphylococcus aureus and Lugdunensis were found to be decreased. That essentially summarizes it. Did you have some experience with this data? Was it metagenomic data or 16S sequencing, if you remember? It was metagenomic sequencing. Did you process the data yourself? No, the dataset was already pre-processed when I received it. I recently had a student working on this, and indeed, it is a large dataset that requires considerable time to analyze. I believe this is common in bioinformatics. You have worked on quite diverse topics, including the microbiome in dermatitis, but you also mentioned single-cell data and antibody-related projects. This current project involves multi-omics data, including microbiome profiles, clinical markers, and a small set of plasma metabolites. It is not a classic large-scale dataset, but it presents its own challenges, such as integrating time-series data with static measurements.\\n\\nSpecifically, most of our datasets pertain to individuals with overweight and obesity, focusing on metabolic deterioration leading to type 2 diabetes. I am curious whether you are particularly drawn to a specific biological question or if your motivation lies more in the methodological aspects of the projects you choose. Is it the biological question or the methodological challenge that guides your selection?\\n\\nI would say it is about 70% the methods. I am very interested in scientific machine learning, which combines different modeling approaches. Nutrition is one of my favorite topics; I have been curious about it even before studying biology. In my country, nutrition is an unusual topic, so I have never considered the biological question as the primary driver for choosing a project. Instead, I focus on what I can do and whether I enjoy the work. Among all topics, I think nutrition is a valuable field to contribute to, especially because many people do not understand how to eat properly or what happens when they consume certain foods. The personalized approach to nutrition is particularly interesting to investigate.\\n\\nI believe I have answered these questions more quickly than expected. I have one final question: you are currently living in the Netherlands, having moved here and experienced the cultural and culinary differences compared to your home country. I am wondering whether you see yourself staying here long-term. Are you comfortable living in the Netherlands, and would this not be a barrier to remaining here for an extended period? When I first moved here, I intended to stay only temporarily to complete my master's degree. However, within the first month, I quickly changed my mind because I genuinely enjoy living here. I have spent my entire life in Rome, and I came here with my partner, who is also a bioinformatician. Together, we decided to stay longer. I appreciate the educational system here and aspire to pursue a PhD; I could never have imagined doing so in Italy. This is not due to the quality of education per se, but rather because of the differences in infrastructure and the organization of research, which are markedly better here. I have developed a strong affinity for the academic environment here, and I also enjoy living here outside of work. For example, biking is very pleasant, and I find the weather much better than in Rome, which is often very hot—though some may disagree with me on that point. Overall, I am quite convinced that this is the right place for me.\\n\\nRegarding your question about collaborations and data generation, the current plan does not include generating new data, as there is no funding allocated for that purpose at this time. Instead, we intend to primarily reuse existing data from our collaborators. Initially, the proposal outlined the generation of synthetic data to develop the framework. This approach allows us to ensure that the model learns the intended patterns. Much of the framework development will rely on synthetic data created through a combination of computational models and artificially spiked microbiome datasets obtained from public databases.\\n\\nFor model validation, we have established collaborations primarily with groups in Bachen and Maastricht, who conduct numerous nutritional trials. They have agreed to share datasets comprising microbiome profiles, meal responses, and immune data. These datasets will enable us to rigorously test and validate the models, as well as to uncover new biological insights into how the microbiome influences metabolic resilience and how this relationship may change following dietary interventions. Additionally, I am exploring the possibility of establishing a collaboration with a group in Amsterdam. That aspect is not entirely finalized yet, but I believe it should be applicable to some of the studies there, particularly those investigating fecal transplants. The primary objective is to reutilize existing data, as there are currently no plans to generate new data. However, we do have access to datasets from multiple studies involving slightly different populations and various dietary interventions, which we can employ to apply our models and thereby derive novel biological insights. \\n\\nRegarding your question about the weekly schedule and supervision: as I mentioned, I currently supervise only two PhD students, but I also work with several master's students. My supervision style tends to be adaptable, tailored to the individual needs of each student. From my experience, some students prefer more frequent, albeit brief, meetings to maintain regular check-ins, which provides them with greater confidence. For master's students, this can mean weekly meetings, while others prefer biweekly meetings to allow sufficient time to generate results before discussing them. I am quite flexible and willing to adjust the frequency of meetings based on what works best for the student and the stage of the project. \\n\\nOccasionally, we may require more frequent meetings, but during periods with many holidays or heavy teaching commitments, meetings may be less frequent. Typically, for my PhD students, we meet every two weeks. These meetings can be short if the code is running smoothly and no major issues have arisen. Conversely, they can be longer when we are developing new ideas or reviewing results for a publication. Thus, the schedule is not rigid; meetings are flexible and responsive to current needs.\\n\\nWe recently relocated to a new building in Eindhoven, where all of us are now on the same floor. The PhD students work in larger rooms accommodating between four and eight students, situated directly across the corridor from my office. This proximity facilitates informal interactions, such as having lunch together or casual encounters at the coffee machines. Students often come by my office to discuss significant or unexpected results or to address emails related to papers. Therefore, communication is not confined to scheduled meetings; it is quite fluid and responsive. \\n\\nHaving spent some time in the Netherlands yourself, you may have noticed that universities here tend to maintain a relatively flat hierarchy. We have deliberately fostered an informal atmosphere where students feel comfortable approaching us whenever they have questions or concerns. Initially, this informality was quite unfamiliar to me, as I was accustomed to a more formal mode of communication with professors, but I am gradually adapting. We strive to maintain this openness as much as possible. Currently, the doctoral candidates are predominantly Dutch. One of our associate professors is from Italy, and we also have a visiting PhD student from Italy, contributing to a reasonably diverse academic community. Although it was more diverse in the past, the staff remains quite international: the full professor is Dutch, Frederica hails from Treviso, I am originally from Ireland, and we have a colleague named Dragon from Macedonia. Thus, the group is notably international. While many PhD students are Dutch, the presence of visiting students means that lunches and meetings are typically conducted in English. Across the university, much of the official information is provided entirely in English; Dutch is no longer the primary language for these communications.\\n\\nRegarding language of instruction, the bachelor's program is officially offered in Dutch, whereas the master's program is conducted in English. All meetings and staff-related website information are in English, which facilitates inclusivity.\\n\\nConcerning work arrangements, I would like to inquire whether you would be amenable to a hybrid model rather than full-time on-site presence. We do permit working from home; some PhD students typically work remotely one to two days per week. It is preferable, however, for students to be physically present as much as possible, particularly on Wednesdays when we hold our group meetings. Physical presence is also encouraged for other meetings and for social interaction within the office environment. Maintaining in-person engagement fosters a stronger sense of community among the group and with students. Therefore, full-time remote work throughout the week is generally discouraged.\\n\\nYour current arrangement of three to four days on-site and one to two days working from home aligns well with our expectations. Regarding travel compensation, I understand that, at least in your case, the provisions adequately cover your commuting expenses, which is important, especially considering you do not reside in Eindhoven. This is a practical consideration we take seriously. Very well. I do not have many questions at this point. As I mentioned, I have meetings scheduled with two additional individuals today. My plan is to inform you of the outcome by early next week, either Monday or Tuesday. We have provisionally scheduled the second interview for the 20th of June.\\n\\nExcellent. The panel for the second interview will consist of myself, Natal van Riel, who is the head of the group, and Frederica Edwardi, an associate professor within the group. I will be in contact with you shortly and provide further details. The intention is for you to prepare a brief presentation, introducing yourself, your academic background, and your master’s thesis. This presentation should be flexible but not exceed ten minutes.\\n\\nAdditionally, I will share a paper authored by one of my former PhD students that addresses scientific machine learning. Along with this, I will provide more information regarding a request for a proposal demonstrating your understanding of the method and how you might envision its application within the context of the microbiome.\\n\\nI will reach out to you by Tuesday with further updates. Thank you very much for your time. It was a pleasure to meet you. Goodbye.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(final_rewritten_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daily_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
