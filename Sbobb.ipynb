{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import yt_dlp\n",
    "import assemblyai as aai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "###############################################################################\n",
    "# 2. ASSEMBLYAI TRANSCRIPTION\n",
    "###############################################################################\n",
    "\n",
    "def extract_audio_from_youtube(youtube_url: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the best available audio URL (m4a format) from the given YouTube URL.\n",
    "    Optionally uses a cookies file if the environment variable YOUTUBE_COOKIES is set.\n",
    "    \"\"\"\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"cookiesfrombrowser\": ('firefox',),\n",
    "        \"verbose\": 'False'\n",
    "    }\n",
    "    \n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(youtube_url)\n",
    "\n",
    "    # Iterate over formats in reverse (best quality first) and pick one with audio only\n",
    "    for fmt in reversed(info.get(\"formats\", [])):\n",
    "        if fmt.get(\"acodec\") != \"none\" and fmt.get(\"ext\") == \"m4a\":\n",
    "            return fmt[\"url\"]\n",
    "\n",
    "def transcribe_audio_assemblyai(audio_url_or_path: str, language_code: str = \"en\") -> aai.Transcript:\n",
    "    \"\"\"\n",
    "    Transcribe the audio from the given URL or local file path using AssemblyAI.\n",
    "    If a YouTube URL is provided, it automatically extracts the audio URL.\n",
    "    Returns the transcript object.\n",
    "    \"\"\"\n",
    "    # If the input appears to be a YouTube URL, extract the audio URL.\n",
    "    if \"youtube.com\" in audio_url_or_path or \"youtu.be\" in audio_url_or_path:\n",
    "        print(\"YouTube URL detected. Extracting audio URL...\")\n",
    "        audio_url_or_path = extract_audio_from_youtube(audio_url_or_path)\n",
    "    \n",
    "    # Set up AssemblyAI\n",
    "    aai.settings.api_key = ASSEMBLYAI_API_KEY\n",
    "    config = aai.TranscriptionConfig(language_code=language_code)\n",
    "    transcriber = aai.Transcriber(config=config)\n",
    "\n",
    "    # Start transcription\n",
    "    transcript = transcriber.transcribe(audio_url_or_path)\n",
    "\n",
    "    # Poll for completion\n",
    "    while transcript.status not in ['completed', 'error']:\n",
    "        print(f\"Transcription status: {transcript.status}. Waiting...\")\n",
    "        time.sleep(5)  # Wait for 5 seconds before checking again\n",
    "        transcript = transcriber.get_transcription(transcript.id)\n",
    "\n",
    "    # Check for errors\n",
    "    if transcript.status == aai.TranscriptStatus.error:\n",
    "        raise RuntimeError(f\"Transcription failed: {transcript.error}\")\n",
    "\n",
    "    return transcript\n",
    "\n",
    "###############################################################################\n",
    "# 3. CHUNKING THE TRANSCRIPT\n",
    "###############################################################################\n",
    "\n",
    "def chunk_text_by_paragraphs(transcript: aai.Transcript, chunk_word_target: int = 600) -> list:\n",
    "    \"\"\"\n",
    "    Splits the transcript into chunks based on its paragraphs, aiming for about\n",
    "    `chunk_word_target` words each. Accumulates paragraphs until the target is reached.\n",
    "    \n",
    "    Returns a list of textual chunks (strings).\n",
    "    \"\"\"\n",
    "    paragraphs = transcript.get_paragraphs()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_word_count = 0\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph_text = paragraph.text.strip()\n",
    "        if not paragraph_text:\n",
    "            continue  # Skip empty paragraphs\n",
    "\n",
    "        paragraph_word_count = len(paragraph_text.split())\n",
    "\n",
    "        # If adding this paragraph exceeds the target and current chunk is not empty, create a new chunk\n",
    "        if (current_word_count + paragraph_word_count) > chunk_word_target and current_chunk:\n",
    "            chunk = \"\\n\".join(current_chunk)\n",
    "            chunks.append(chunk)\n",
    "            current_chunk = []\n",
    "            current_word_count = 0\n",
    "\n",
    "        # Add the paragraph to the current chunk\n",
    "        current_chunk.append(paragraph_text)\n",
    "        current_word_count += paragraph_word_count\n",
    "\n",
    "    # Add any remaining paragraphs as the last chunk\n",
    "    if current_chunk:\n",
    "        chunk = \"\\n\".join(current_chunk)\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "###############################################################################\n",
    "# 4. OPENAI REWRITING (PAGE-BY-PAGE)\n",
    "###############################################################################\n",
    "def rewrite_chunk_with_openai(chunk_text: str,\n",
    "                              model: str = OPENAI_MODEL,\n",
    "                              prev_summary: str = \"\") -> str:\n",
    "    \"\"\"\n",
    "    Sends a chunk of text to OpenAI for rewriting in a 'professorial' register.\n",
    "\n",
    "    Optionally includes `prev_summary` – a short summary of all previously\n",
    "    processed chunks – as context for better continuity across chunks.\n",
    "\n",
    "    Returns the revised chunk as a string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Build system prompt with instructions\n",
    "    system_prompt = (\n",
    "        \"You are an expert in rewriting transcripts with a professorial register. \"\n",
    "        \"You will receive fragments of a university lesson transcript generated \"\n",
    "        \"from an audio recording. Your role is to correct grammar, punctuation, \"\n",
    "        \"and spelling, fix words that may be misrecognized, remove filler words, \"\n",
    "        \"and elevate the text to an academic standard. Output only the revised \"\n",
    "        \"transcript text in plain text, without titles, markdown, or other formatting. \"\n",
    "        \"Maintain context as if it were in medias res.\"\n",
    "    )\n",
    "\n",
    "    # Build user prompt with the chunk, plus the short summary of prior chunks\n",
    "    # The summary is for context only; it helps the model keep track of earlier topics.\n",
    "    if prev_summary:\n",
    "        user_prompt = (\n",
    "            f\"Here is a short summary of what has come before:\\n{prev_summary}\\n\\n\"\n",
    "            f\"Now, rewrite the following chunk:\\n\\n{chunk_text}\\n\\n\"\n",
    "            \"Output only the revised text. Do not add extra commentary or formatting.\"\n",
    "        )\n",
    "    else:\n",
    "        user_prompt = (\n",
    "            f\"Now, rewrite the following chunk:\\n\\n{chunk_text}\\n\\n\"\n",
    "            \"Output only the revised text. Do not add extra commentary or formatting.\"\n",
    "        )\n",
    "\n",
    "    # Call OpenAI ChatCompletion using the client\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.2,  # Keep temperature low for consistent rewriting\n",
    "        max_tokens=1500,   # Enough tokens to handle rewriting a ~600-word chunk\n",
    "    )\n",
    "\n",
    "    revised_text = response.choices[0].message.content\n",
    "    return revised_text.strip()\n",
    "\n",
    "def summarize_text_with_openai(text: str,\n",
    "                               model: str = \"chatgpt-4o-mini\") -> str:\n",
    "    \"\"\"\n",
    "    Summarizes the given text in a couple of sentences to maintain context\n",
    "    for future rewriting chunks.\n",
    "    \"\"\"\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are a concise and precise summarizer. Summarize the following text \"\n",
    "        \"in one sentence, focusing on the key ideas. Keep it short. Do not referes \"\n",
    "        \"to the text itself, just provide a single sentence that capture the kay ideas.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = f\"Text to summarize:\\n{text}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt},\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary.strip()\n",
    "\n",
    "def get_word_count(text: str) -> int:\n",
    "    \"\"\"\n",
    "    Returns the word count of the given text.\n",
    "    \"\"\"\n",
    "    return len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# 1. CONFIGURATION\n",
    "###############################################################################\n",
    "\n",
    "# Load environment variables from config.env\n",
    "load_dotenv('./config.env')\n",
    "\n",
    "# Retrieve API keys from environment variables\n",
    "ASSEMBLYAI_API_KEY = os.getenv(\"ASSEMBLYAI_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Validate API keys\n",
    "if not ASSEMBLYAI_API_KEY:\n",
    "    raise ValueError(\"ASSEMBLYAI_API_KEY not found in config.env\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY not found in config.env\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "# client = OpenAI(api_key=\"<DeepSeek API Key>\", base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# Define OpenAI model to use\n",
    "OPENAI_MODEL = \"chatgpt-4o-mini\"  # Ensure this model is accessible with your API key\n",
    "\n",
    "# Define chunking parameters\n",
    "CHUNK_WORD_TARGET = 500  # Target words per chunk\n",
    "MAX_SUMMARY_WORDS = 250  # Maximum words in running summary before summarization\n",
    "ENABLE_SUMMARY_SUMMARIZATION = True  # Toggle for summary summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribing audio... please wait.\n",
      "YouTube URL detected. Extracting audio URL...\n",
      "Extracting cookies from firefox\n",
      "Extracted 1792 cookies from firefox\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=9-Jl0dxWQs8&pp=ygUUaG93IGxsbXMgc3RvcmUgZmFjdHM%3D\n",
      "[youtube] 9-Jl0dxWQs8: Downloading webpage\n",
      "[youtube] 9-Jl0dxWQs8: Downloading tv client config\n",
      "[youtube] 9-Jl0dxWQs8: Downloading player 82345d49\n",
      "[youtube] 9-Jl0dxWQs8: Downloading tv player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: ffmpeg not found. The downloaded format may not be the best available. Installing ffmpeg is strongly recommended: https://github.com/yt-dlp/yt-dlp#dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted audio URL: https://rr5---sn-5hnekn7l.googlevideo.com/videoplayback?expire=1742395608&ei=eITaZ__DA5qL6dsP1JeNiQ0&ip=213.39.100.109&id=o-AMg0v59HJAgHBHBvO-PbK_goChCFi2c_okbjGdQnpIuD&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&met=1742374008%2C&mh=1U&mm=31%2C29&mn=sn-5hnekn7l%2Csn-5hne6nz6&ms=au%2Crdu&mv=m&mvi=5&pl=24&rms=au%2Cau&initcwndbps=2485000&siu=1&bui=AccgBcMD0QLsVAjg9eqU6HXi6s79yWdKyB64ekzlK8EQGbr76tV6PXSGpWDc4NW9OqcouSs1&vprv=1&svpuc=1&xtags=acont%3Doriginal%3Alang%3Den&mime=audio%2Fmp4&ns=h40OYPrqnVs4Dalkp9CpRngQ&rqh=1&gir=yes&clen=22047987&dur=1362.291&lmt=1730836166011665&mt=1742373480&fvip=5&keepalive=yes&lmw=1&c=TVHTML5&sefc=1&txp=4532434&n=nsVKog58DDJMAA&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Csiu%2Cbui%2Cvprv%2Csvpuc%2Cxtags%2Cmime%2Cns%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAMfXFwK-QAIMNpvc-BAwcuWxVkE6AGCLmFUylS5OelIMAiBVRKysaO3ZiFbekpadXUVEz1VIzTZ7tJsYdONYfB0Vsw%3D%3D&lsparams=met%2Cmh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl%2Crms%2Cinitcwndbps&lsig=AFVRHeAwRAIgVXXfyXTZw7biLBUGLL1hFDhdfdusxHJBgE7jXlCgnIsCIAhZyqejTxovPLnaf5ff9W25b8EpALuVTfLtqOs8_Xlp\n",
      "Transcription complete.\n"
     ]
    }
   ],
   "source": [
    "# 1) Transcribe audio\n",
    "# You can point to a local file, remote URL or a YouTube video. E.g.:\n",
    "# audio_source = \"https://assembly.ai/path_to_your_audio_file.mp3\"\n",
    "# or\n",
    "# audio_source = \"./local_file.mp3\"\n",
    "# or\n",
    "# audio_source = \"https://www.youtube.com/watch?v=YOUR_VIDEO\"\n",
    "audio_source = input('Path to audio file: ')  # Replace with your audio file path or URL\n",
    "\n",
    "print(\"Transcribing audio... please wait.\")\n",
    "try:\n",
    "    full_transcript_text = transcribe_audio_assemblyai(audio_source, language_code='en')\n",
    "except RuntimeError as e:\n",
    "    print(str(e))\n",
    "\n",
    "print(\"Transcription complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting transcript into chunks based on paragraphs...\n",
      "Created 2 chunk(s) of ~500 words each.\n"
     ]
    }
   ],
   "source": [
    "# 2) Chunk the transcript using paragraphs\n",
    "print(\"Splitting transcript into chunks based on paragraphs...\")\n",
    "chunks = chunk_text_by_paragraphs(full_transcript_text, chunk_word_target=CHUNK_WORD_TARGET)\n",
    "print(f\"Created {len(chunks)} chunk(s) of ~{CHUNK_WORD_TARGET} words each.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewriting chunk 1/2...\n",
      "Summary for chunk 1: Il modello concettuale sviluppato utilizza MySQL Workbench per rappresentare dati di sequenziamento RNA di cellule sane e tumorali, strutturati in un'entità principale \"Cellula\" con sottoentità disgiunte \"Healthy Cell\" e \"Tumor Cell\", collegate a un'entità \"Gene\" tramite relazioni molti-a-molti e a una tabella \"Predictions\" per le cellule tumorali tramite una relazione uno-a-uno.\n",
      "Rewriting chunk 2/2...\n",
      "Summary for chunk 2: Il testo descrive la struttura di un database relazionale per analisi cellulari, includendo tabelle per predizioni tumorali, componenti principali (PCA), embedding (UMAP), geni e marker, con relazioni uno-a-uno e gerarchiche tra entità, e fornisce istruzioni per implementarlo in MySQL Workbench con chiavi primarie, esterne e vincoli di integrità.\n"
     ]
    }
   ],
   "source": [
    "# 3) For each chunk, rewrite with OpenAI\n",
    "final_rewritten_text = []\n",
    "running_summary = \"\"  # Will accumulate short summaries of prior chunks\n",
    "\n",
    "for i, chunk_text in enumerate(chunks, start=1):\n",
    "    print(f\"Rewriting chunk {i}/{len(chunks)}...\")\n",
    "\n",
    "    # Rewrite the chunk\n",
    "    try:\n",
    "        revised_text = rewrite_chunk_with_openai(\n",
    "            chunk_text=chunk_text,\n",
    "            model=OPENAI_MODEL,\n",
    "            prev_summary=running_summary\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error rewriting chunk {i}: {str(e)}\")\n",
    "        continue  # Skip to the next chunk\n",
    "\n",
    "    # Append the revised text to our final output\n",
    "    final_rewritten_text.append(revised_text)\n",
    "\n",
    "    # Summarize this revised chunk to update context\n",
    "    try:\n",
    "        chunk_summary = summarize_text_with_openai(revised_text, model=OPENAI_MODEL)\n",
    "        print(f\"Summary for chunk {i}: {chunk_summary}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Error summarizing chunk {i}: {str(e)}\")\n",
    "        chunk_summary = \"\"\n",
    "\n",
    "    # Append new summary to the running summary\n",
    "    # Check if summarization of the running summary is enabled\n",
    "    if ENABLE_SUMMARY_SUMMARIZATION:\n",
    "        running_summary += f\" {chunk_summary}\"\n",
    "        # Check if running_summary exceeds MAX_SUMMARY_WORDS\n",
    "        if get_word_count(running_summary) > MAX_SUMMARY_WORDS:\n",
    "            print(\"Running summary exceeds maximum word limit. Summarizing the running summary...\")\n",
    "            try:\n",
    "                summarized_running_summary = summarize_text_with_openai(running_summary, model=OPENAI_MODEL)\n",
    "                running_summary = summarized_running_summary\n",
    "                print(f\"Summarized running summary: {running_summary}\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error summarizing running summary: {str(e)}\")\n",
    "                # Optionally, you can reset the running_summary or keep it as is\n",
    "    else:\n",
    "        running_summary += f\" {chunk_summary}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carosia GPT O1. Ho un corso relativo alla gestione dei dati di ricerca (Research Data Management) e il mio compito consiste nell\\'implementare, utilizzando MySQL Workbench, un modello concettuale che ho creato a partire dai miei dati, con il tuo supporto precedente. Per cominciare, ti invio il report dello studio da cui ho tratto i dati, che ho elaborato personalmente. Successivamente, ti descriverò nel dettaglio come ho strutturato questo modello concettuale, anche grazie al tuo aiuto.\\n\\nIl modello concettuale che ho sviluppato si basa su due oggetti dati, ossia due dataset di sequenziamento dell\\'RNA a singola cellula: uno relativo a cellule sane e l\\'altro a cellule tumorali. Utilizzando il dataset delle cellule sane, ho generato delle predizioni applicate al dataset delle cellule tumorali.\\n\\nLa struttura del modello concettuale è la seguente. La prima entità è un\\'entità principale denominata \"Cellula\", che contiene cinque attributi: Cell ID, Cell Cycle Fraction, Ys Cycling, Donor e Chemistry. Da questa entità principale si diramano due sottoentità: \"Healthy Cell\" e \"Tumor Cell\". \\n\\nGli attributi che ho menzionato, associati all\\'entità principale \"Cellula\", sono comuni a entrambe le sottoentità. Tuttavia, ciascuna sottoentità possiede anche attributi specifici. Le due sottoentità sono disgiunte, il che significa che i dati presenti nell\\'entità principale appartengono esclusivamente a una delle due sottoentità, ossia o \"Healthy Cell\" o \"Tumor Cell\". \\n\\nPer quanto riguarda la sottoentità \"Healthy Cell\", gli attributi specifici includono: Cell ID (dell\\'entità \"Cellula\"), Batch, Stage, Scampi Clusters e Cytograph Clusters. Per la sottoentità \"Tumor Cell\", gli attributi specifici sono: Tumor Cell ID, Age, Clones, Total UMIs, Sample ID, Clusters e Dissociation.\\n\\nCiascuna di queste sottoentità è collegata a una nuova entità denominata \"Gene\" attraverso una relazione di tipo \"esprime\". Pertanto, sia \"Healthy Cell\" sia \"Tumor Cell\" sono associate alla stessa entità \"Gene\", che presenta i seguenti attributi: Name, Ensemble ID, Chromosome, Strand, Start, End, Selected, Highly Variable e Mean. La relazione tra \"Healthy Cell\" e \"Gene\" e quella tra \"Tumor Cell\" e \"Gene\" sono entrambe di tipo molti-a-molti. Queste relazioni saranno rappresentate da tabelle di espressione genica nelle cellule, con due tabelle distinte: una per \"Healthy Cell\" e una per \"Tumor Cell\".\\n\\nInfine, la sottoentità \"Tumor Cell\" è collegata, tramite una relazione uno-a-uno, a una tabella o entità denominata \"Predictions\".',\n",
       " 'La tabella \"Predictions\" contiene, per ogni \"Tumor Cell ID,\" diverse predizioni generate attraverso metodi distinti. Una colonna rappresenta i risultati ottenuti con il metodo Mahalanobis Distance, un\\'altra con il metodo Random Forest, una terza colonna riporta la probabilità massima delle predizioni assegnate dal Random Forest, e un\\'ulteriore colonna, denominata \"GB Map Predicted,\" contiene i risultati di un altro metodo. Inoltre, dall\\'entità padre \"Cellula\" si diramano altre due entità, \"PCA\" e \"UMAP.\" La relazione tra \"PCA\" e \"Cellula\" è uno-a-uno, poiché ogni riga della tabella \"Cellula\" ha una corrispondente riga in \"PCA.\" In \"PCA\" sono assegnati 50 principal components per ogni cellula, distribuiti su 50 colonne. A ciò si aggiunge una colonna denominata \"Cell Type,\" che distingue tra cellule sane (\"Healthy\") e tumorali (\"Tumor\"). \\n\\nL\\'entità \"UMAP\" è strutturata in modo simile a \"PCA\" e anch\\'essa è collegata a \"Cellula\" tramite una relazione uno-a-uno. Contiene il \"Cell ID,\" il tipo di cellula (Healthy o Tumor) e le due dimensioni di embedding generate da UMAP. \\n\\nInfine, l\\'entità \"Markers\" è collegata all\\'entità \"Gene.\" \"Markers\" rappresenta una sottocategoria di \"Gene,\" il che implica che tutti i marker sono presenti in \"Gene,\" ma non tutti i geni sono marker. La relazione tra \"Gene\" e \"Markers\" è denominata \"Is\" ed è uno-a-uno: ogni gene può corrispondere a un solo marker, mentre un marker può essere associato a zero o un gene.\\n\\nPer implementare questi concetti in MySQL Workbench, è necessario seguire una serie di passaggi. Iniziare con la creazione delle tabelle principali, definendo le chiavi primarie per ogni entità. Per \"Cellula,\" utilizzare un attributo univoco come \"Cell ID\" come chiave primaria. Le entità \"Healthy Cell\" e \"Tumor Cell\" devono essere collegate a \"Cellula\" tramite una relazione gerarchica, utilizzando \"Cell ID\" come chiave esterna. \\n\\nPer \"PCA\" e \"UMAP,\" creare tabelle separate con \"Cell ID\" come chiave esterna che si riferisce alla chiave primaria di \"Cellula.\" Assicurarsi che le tabelle includano i rispettivi attributi, come i 50 principal components per \"PCA\" e le due dimensioni di embedding per \"UMAP,\" oltre alla colonna \"Cell Type.\" Se si desidera unificare le tabelle di \"PCA\" e \"UMAP\" per cellule sane e tumorali, è possibile farlo direttamente in MySQL Workbench utilizzando una query di unione o, in alternativa, consolidare i dati in un\\'unica tabella prima dell\\'importazione.\\n\\nPer \"Predictions,\" definire \"Tumor Cell ID\" come chiave esterna che si riferisce alla chiave primaria di \"Tumor Cell.\" Ogni colonna della tabella deve rappresentare un attributo specifico delle predizioni, come i risultati dei metodi Mahalanobis Distance, Random Forest, e GB Map Predicted.\\n\\nInfine, per \"Gene\" e \"Markers,\" definire \"Gene ID\" come chiave primaria in \"Gene\" e utilizzarlo come chiave esterna in \"Markers.\" La relazione uno-a-uno può essere implementata attraverso vincoli di unicità sulla chiave esterna in \"Markers.\" \\n\\nSi consiglia di iniziare con la creazione della tabella \"Cellula\" e delle sue entità figlie, seguita dalle tabelle \"PCA\" e \"UMAP,\" e infine dalle tabelle \"Predictions,\" \"Gene,\" e \"Markers.\" Prestare attenzione alla definizione delle chiavi esterne e dei vincoli di integrità referenziale per garantire la coerenza del modello.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rewritten_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL REWRITTEN TRANSCRIPT ===\n",
      "\n",
      "Carosia GPT O1. Ho un corso relativo alla gestione dei dati di ricerca (Research Data Management) e il mio compito consiste nell'implementare, utilizzando MySQL Workbench, un modello concettuale che ho creato a partire dai miei dati, con il tuo supporto precedente. Per cominciare, ti invio il report dello studio da cui ho tratto i dati, che ho elaborato personalmente. Successivamente, ti descriverò nel dettaglio come ho strutturato questo modello concettuale, anche grazie al tuo aiuto.\n",
      "\n",
      "Il modello concettuale che ho sviluppato si basa su due oggetti dati, ossia due dataset di sequenziamento dell'RNA a singola cellula: uno relativo a cellule sane e l'altro a cellule tumorali. Utilizzando il dataset delle cellule sane, ho generato delle predizioni applicate al dataset delle cellule tumorali.\n",
      "\n",
      "La struttura del modello concettuale è la seguente. La prima entità è un'entità principale denominata \"Cellula\", che contiene cinque attributi: Cell ID, Cell Cycle Fraction, Ys Cycling, Donor e Chemistry. Da questa entità principale si diramano due sottoentità: \"Healthy Cell\" e \"Tumor Cell\". \n",
      "\n",
      "Gli attributi che ho menzionato, associati all'entità principale \"Cellula\", sono comuni a entrambe le sottoentità. Tuttavia, ciascuna sottoentità possiede anche attributi specifici. Le due sottoentità sono disgiunte, il che significa che i dati presenti nell'entità principale appartengono esclusivamente a una delle due sottoentità, ossia o \"Healthy Cell\" o \"Tumor Cell\". \n",
      "\n",
      "Per quanto riguarda la sottoentità \"Healthy Cell\", gli attributi specifici includono: Cell ID (dell'entità \"Cellula\"), Batch, Stage, Scampi Clusters e Cytograph Clusters. Per la sottoentità \"Tumor Cell\", gli attributi specifici sono: Tumor Cell ID, Age, Clones, Total UMIs, Sample ID, Clusters e Dissociation.\n",
      "\n",
      "Ciascuna di queste sottoentità è collegata a una nuova entità denominata \"Gene\" attraverso una relazione di tipo \"esprime\". Pertanto, sia \"Healthy Cell\" sia \"Tumor Cell\" sono associate alla stessa entità \"Gene\", che presenta i seguenti attributi: Name, Ensemble ID, Chromosome, Strand, Start, End, Selected, Highly Variable e Mean. La relazione tra \"Healthy Cell\" e \"Gene\" e quella tra \"Tumor Cell\" e \"Gene\" sono entrambe di tipo molti-a-molti. Queste relazioni saranno rappresentate da tabelle di espressione genica nelle cellule, con due tabelle distinte: una per \"Healthy Cell\" e una per \"Tumor Cell\".\n",
      "\n",
      "Infine, la sottoentità \"Tumor Cell\" è collegata, tramite una relazione uno-a-uno, a una tabella o entità denominata \"Predictions\".\n",
      "La tabella \"Predictions\" contiene, per ogni \"Tumor Cell ID,\" diverse predizioni generate attraverso metodi distinti. Una colonna rappresenta i risultati ottenuti con il metodo Mahalanobis Distance, un'altra con il metodo Random Forest, una terza colonna riporta la probabilità massima delle predizioni assegnate dal Random Forest, e un'ulteriore colonna, denominata \"GB Map Predicted,\" contiene i risultati di un altro metodo. Inoltre, dall'entità padre \"Cellula\" si diramano altre due entità, \"PCA\" e \"UMAP.\" La relazione tra \"PCA\" e \"Cellula\" è uno-a-uno, poiché ogni riga della tabella \"Cellula\" ha una corrispondente riga in \"PCA.\" In \"PCA\" sono assegnati 50 principal components per ogni cellula, distribuiti su 50 colonne. A ciò si aggiunge una colonna denominata \"Cell Type,\" che distingue tra cellule sane (\"Healthy\") e tumorali (\"Tumor\"). \n",
      "\n",
      "L'entità \"UMAP\" è strutturata in modo simile a \"PCA\" e anch'essa è collegata a \"Cellula\" tramite una relazione uno-a-uno. Contiene il \"Cell ID,\" il tipo di cellula (Healthy o Tumor) e le due dimensioni di embedding generate da UMAP. \n",
      "\n",
      "Infine, l'entità \"Markers\" è collegata all'entità \"Gene.\" \"Markers\" rappresenta una sottocategoria di \"Gene,\" il che implica che tutti i marker sono presenti in \"Gene,\" ma non tutti i geni sono marker. La relazione tra \"Gene\" e \"Markers\" è denominata \"Is\" ed è uno-a-uno: ogni gene può corrispondere a un solo marker, mentre un marker può essere associato a zero o un gene.\n",
      "\n",
      "Per implementare questi concetti in MySQL Workbench, è necessario seguire una serie di passaggi. Iniziare con la creazione delle tabelle principali, definendo le chiavi primarie per ogni entità. Per \"Cellula,\" utilizzare un attributo univoco come \"Cell ID\" come chiave primaria. Le entità \"Healthy Cell\" e \"Tumor Cell\" devono essere collegate a \"Cellula\" tramite una relazione gerarchica, utilizzando \"Cell ID\" come chiave esterna. \n",
      "\n",
      "Per \"PCA\" e \"UMAP,\" creare tabelle separate con \"Cell ID\" come chiave esterna che si riferisce alla chiave primaria di \"Cellula.\" Assicurarsi che le tabelle includano i rispettivi attributi, come i 50 principal components per \"PCA\" e le due dimensioni di embedding per \"UMAP,\" oltre alla colonna \"Cell Type.\" Se si desidera unificare le tabelle di \"PCA\" e \"UMAP\" per cellule sane e tumorali, è possibile farlo direttamente in MySQL Workbench utilizzando una query di unione o, in alternativa, consolidare i dati in un'unica tabella prima dell'importazione.\n",
      "\n",
      "Per \"Predictions,\" definire \"Tumor Cell ID\" come chiave esterna che si riferisce alla chiave primaria di \"Tumor Cell.\" Ogni colonna della tabella deve rappresentare un attributo specifico delle predizioni, come i risultati dei metodi Mahalanobis Distance, Random Forest, e GB Map Predicted.\n",
      "\n",
      "Infine, per \"Gene\" e \"Markers,\" definire \"Gene ID\" come chiave primaria in \"Gene\" e utilizzarlo come chiave esterna in \"Markers.\" La relazione uno-a-uno può essere implementata attraverso vincoli di unicità sulla chiave esterna in \"Markers.\" \n",
      "\n",
      "Si consiglia di iniziare con la creazione della tabella \"Cellula\" e delle sue entità figlie, seguita dalle tabelle \"PCA\" e \"UMAP,\" e infine dalle tabelle \"Predictions,\" \"Gene,\" e \"Markers.\" Prestare attenzione alla definizione delle chiavi esterne e dei vincoli di integrità referenziale per garantire la coerenza del modello.\n",
      "Final transcript saved to final_transcript.txt\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# 4) Output the final revised text\n",
    "print(\"\\n=== FINAL REWRITTEN TRANSCRIPT ===\\n\")\n",
    "final_text = \"\\n\".join(final_rewritten_text)\n",
    "print(final_text)\n",
    "\n",
    "# Optionally, save the final text to a file\n",
    "# Uncomment the lines below to enable saving to a text file\n",
    "\n",
    "try:\n",
    "    with open(f\"audio_ila_model_{OPENAI_MODEL}.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(final_text)\n",
    "    print(\"Final transcript saved to final_transcript.txt\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving final transcript: {str(e)}\")\n",
    "\n",
    "print(\"\\nDone.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
